{"pages":[{"title":"MONTR√âAL.AI | Montr√©al Artificial Intelligence","text":"Montr√©al.AI Consulting Considering that top AI talent is extremely scarce right now and bearing in mind that consulting the right AI leader can significantly increase your odds of business success, Montr√©al.AI now offers consulting. ‚Äú We want to see more widespread matrix interoperability, life-long learning opportunities and Chief AI Officers who possess the knowledges, the skills and the competencies to orchestrate impactful breakthroughs and tangible economic growth for Fortune 500, governments and interagency partners.‚Äú Montr√©al.AI : The Best in AI ConsultingMontr√©al.AI Consulting : Impactful artificial intelligence. MONTR√âAL.AI | Montr√©al Artificial Intelligence develops and trains completion-oriented women and men with the determination to ensure a fully ‚ÄòJoint Artificial Intelligence Consulting Workforce‚Äô : Intellectually, operationally, organizationally, and technically to solve Humanity‚Äôs toughest challenges. Montr√©al.AI Space | ConsultingMontr√©al.AI Space : A new world age of technical prowesses. ‚ÄúRecognizing that Montreal is a world-class aerospace industry hub and a world leader in artificial intelligence, we‚Äôve created Montr√©al.AI Space.‚Äú ‚Äî Vincent Boucher, Founding Chairman at Montr√©al.AI We are living in a period of unprecedented breakthroughs in science. Montr√©al.AI Space leverages aerospace engineering, applied artificial intelligence and space science researches for use in spaceflight, satellites and space exploration. Near future advances at the intersection of aerospace engineering and artificial intelligence hold out extraordinary prospects for the future of Mankind. Montr√©al.AI Atelier | Tailored Top AI ModelsArtificial Intelligence for the Web ‚Äú Nothing is more powerful than an idea whose time has come. ‚Äú ‚Äî Victor Hugo The Montr√©al.AI Atelier transforms Web sites for the age of artificial intelligence by developing superhuman agents that can learn from experience in the browser and unlock new powerful possibilities : E.g., on a mobile device, the autonomous agents can leverage sensor data (i.e.: gyroscope or accelerometer). All data stays on the client, making AI agents in the browser useful for privacy preserving applications. Fully-Fledged AI Systems : From AI Research to Commercial SuccessesMontr√©al.AI‚Äôs superhuman AI agents can learn from experience, simulate worlds and orchestrate meta-solutions. ‚ÄúYou never change things by fighting the existing reality. To change something, build a new model that makes the existing model obsolete.‚Äú ‚Äî Buckminster Fuller Fully-fledged AI systems can achieve serious revenue. Montr√©al.AI Blockchain | Consulting‚Äú‚Ä¶there is no discrimination against robots or humans in the Ethereum ecosystem‚Ä¶‚Äú ‚Äî Ethereum Foundation Apply AI In Ways Never Thought Of Deploying powerful AI agents on Blockchain ; Developing general-purpose multi-agent DAE ; Evolving Blockchain-based artificial life ; etc. Montr√©al.AI DAOA modality agnostic platform for developing general-purpose AI-first decentralized autonomous organisations (Startups, Government, Institutes, ‚Ä¶) + A toolkit to deploy AI on top of it. AI + Ethereum = Artificial Life (The Economy of Things) Chief AI Officers : C-level AI | Executive Education‚ÄéBuilt on over $1 Million ($1,000,000) in artificial intelligence research Chief AI Officers : C-level AI harnesses the fundamentals of artificial intelligence on a truly global scale and put them to strategically leverage enterprises, governments and institutions with precision engineering. ‚ÄúIn a moment of technological disruption, leadership matters.‚Äú ‚Äî Andrew Ng Success is about actively shaping the game that matters to you. This well-crafted C-level professional keynote pioneers a highly impactful understanding of transformative artificial intelligence strategies, at boardroom level, bringing to life new perspectives for state, national, and international organizations. Participant Profile‚ÄúWe want to see more life-long learning opportunities, across the board matrix interoperability and the development of Chief AI Officers who possess the knowledges, the skills and the competencies to orchestrate impactful breakthroughs and tangible economic growth for Fortune 500, governments and interagency partners in full compliance with our masterplan : The Montr√©al AI-First Conglomerate Overarching Program.‚Äú ‚Äî Vincent Boucher, B. Sc. Physics, M. A. Policy Analysis and M. Sc. Aerospace Engineering (Space Technology), Founding Chairman at Montr√©al.AI Chief AI Officers : C-level AI is designed for the : Board Members; Captains of Industry; Chancellors; Chief Executive Officers; Commanders; Excellences; Global Chairs High-Potential Executives; Iconic Tech Entrepreneurs; Luminaries; Managing Directors; Moguls; Philanthropists; Presidents; Scholars; Successful Entrepreneurs and Financiers; and Visionary Founders ‚Ä¶ who wish to strategically unleash the power of artificial intelligence on a truly global scale. ‚ÄúBreakthrough in machine learning would be worth 10 Microsofts.‚Äú ‚Äî Bill Gates References‚ÄúLast year, the cost of a top, world-class deep learning expert was about the same as a top NFL quarterback prospect. The cost of that talent is pretty remarkable.‚Äú ‚Äî Peter Lee, Microsoft Million-dollar babies ‚Äî The Economist The Battle for Top AI Talent Only Gets Tougher From Here ‚Äî Wired The Tech Oligopoly ‚Äî Part 1 | The New Kingmakers ‚Äî Arif Khan Oracle recently offered an artificial intelligent expert as much as $6 million in total pay as Silicon Valley‚Äôs talent war heats up ‚Äî The Economist A.I. Researchers Are Making More Than $1 Million, Even at a Nonprofit ‚Äî The New York Times Join Montr√©al.AI Consulting ‚Äî A Once-in-a-Lifetime OpportunityMONTR√âAL.AI is starting an effort to bring together the top world-class deep learning experts, captains of industries and leading seasoned executives to build a decisive, preeminent and renowned outstanding AI consulting workforce. To apply to join our pool of outstanding consulting workforce : hr@montreal.ai ‚ÄúIt‚Äôs springtime for AI, and we‚Äôre anticipating a long summer.‚Äú ‚Äî Bill Braun, CIO of Chevron ‚úâÔ∏è Email Us : info@montreal.aiüìû Phone : +1.514.829.8269üåê Website : http://www.montreal.aiüìù LinkedIn : https://www.linkedin.com/in/montrealaiüèõ Headquarters : 350, PRINCE-ARTHUR STREET W., SUITE #2105, MONTREAL [QC], CANADA, H2X 3R4 *Administrative Head Office #AIFirst #Chief AI Officers #MontrealAI #MontrealArtificialIntelligence","link":"/MontrealAI.github.io/consulting/index.html"},{"title":"Montr√©al Artificial Intelligence","text":"AVIS L√âGAL - LEGAL NOTICE‚Äã‚ÄãMATERIALS PROVIDED IN THIS SYSTEM ARE PROVIDED WITHOUT WARRANTY OF ANY KIND AND DOES NOT CONSTITUTE ENDORSEMENT. | LES INFORMATIONS DONN√âES PAR CE SYST√àME SONT FOURNIES SANS GARANTIE D‚ÄôAUCUNE SORTE ET NE CONSTITUENT PAS UNE APPROBATION.‚Äã‚Äã‚úâÔ∏è Email Us : info@montreal.ai‚Äãüåê Website : http://www.montreal.ai/‚Äã‚Äã#AI #AIFirst #MontrealAI #MontrealArtificialIntelligence","link":"/MontrealAI.github.io/legal/index copy.html"},{"title":"Montr√©al Artificial Intelligence","text":"AVIS L√âGAL - LEGAL NOTICETHIS IS A MONTREAL.AI SOFTWARE / SYSTEM. MATERIALS PROVIDED IN THIS SOFTWARE / SYSTEM ARE PROVIDED WITHOUT WARRANTY OF ANY KIND AND DOES NOT CONSTITUTE ENDORSEMENT. THIS SOFTWARE / SYSTEM IS PROVIDED ‚ÄúAS IS‚Äù, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL MONTREAL.AI, THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THIS SOFTWARE / SYSTEM OR THE USE OR OTHER DEALINGS IN THIS SOFTWARE / SYSTEM. EVIDENCE OF UNAUTHORIZED USE MAY BE PROVIDED TO APPROPRIATE PERSONNEL FOR ADMINISTRATIVE, CRIMINAL OR OTHER LEGAL ACTION.‚Äã‚Äã‚Äã‚Äã‚Äã ‚Äã‚úâÔ∏è Email Us : info@montreal.ai‚Äãüìû Phone : +1.514.829.8269‚Äãüåê Website : http://www.montreal.ai‚Äãüìù LinkedIn : https://www.linkedin.com/in/montrealai‚Äãüèõ Headquarters : 350, PRINCE-ARTHUR STREET W., SUITE #2105, MONTREAL [QC], CANADA, H2X 3R4 *Administrative Head Office‚Äã‚Äã#AIFirst #MontrealAI #MontrealArtificialIntelligence","link":"/MontrealAI.github.io/legal/index.html"},{"title":"Montr√©al Artificial Intelligence","text":"Montr√©al.AI Web ‚Äî The Dawn of Artificial IntelligenceArtificial Intelligence for the Web : Converting AI Research into Commercial Successes. At the forefront of AI, deploying superhuman agents that can learn from experience in the browser unlocks new powerful possibilities to apply AI in ways we never thought of! E.g., on a mobile device, the autonomous agent can leverage sensor data (i.e.: gyroscope or accelerometer) and take actions. True understanding comes from agents that learn by ‚Äúseeing‚Äù how they affect the world. All data stays on the client, making AI agents in the browser useful for privacy preserving applications. ‚Äú Artificial Intelligence is about recognising patterns, Artificial Life is about creating patterns. ‚Äú ‚Äî Mizuki Oka et al, #alife2018 A Proof of Concept : Getting Alexa to Respond to Sign LanguageUsing TensorFlow to make an Amazon Echo respond to sign language, by M. A. Singh : Blog Post by by M. A. Singh Code for the Proof of Concept on GitHub Advanced and Impactful Open-Source TechnologiesBringing contributions by scholars recognized as the foremost authorities in their fields, Montr√©al Artificial Intelligence is ahead of trends that will profoundly influence the future of Humanity. Cutting edge open-source technologies proudly used : 1. TensorFlow.jsTraining and Deploying ML Models in the Browser TensorFlow.js uses flexible and intuitive APIs to build and train models from scratch using a low-level JavaScript linear algebra library or a high-level layers API. The TensorFlow.js model converters allows running pre-existing TensorFlow models right in the browser or under Node.js. Pre-existing ML models can be retrained using sensor data connected to the browser, or other client-side data. Three development workflows : Importing an existing, pre-trained model for inference ; Re-training an imported model quickly (transfer learning) with only a small amount of data ; and Authoring (define, train, and run) models directly in the browser. TensorFlow.js AI agents can be trained using reinforcement learning, neuroevolution, or other machine learning methods. There‚Äôs no need to install anything. Just open a webpage, and your AI Agent is ready to run. References : TensorFlow.js TensorFlow dev summit Official TensorFlow.js Launch Introducing TensorFlow.js by Josh Gordon and Sara Robinson Deep Learning in JS - Ashi Krishnan - JSConf EU 2018 TensorFlow.js Gallery 2. Reinforcement LearningGoing Beyond Input-Output Pattern Recognition In the past few years deep reinforcement learning started achieving state-of-the-art results. ‚Äú Reinforcement learning (RL) is the subfield of machine learning concerned with decision making and motor control. It studies how an agent can learn how to achieve goals in a complex, uncertain environment. ‚Äú ‚Äî OpenAI At the bleeding edge of AI, autonomous agents can learn from experience, simulate worlds and orchestrate meta-solutions. Here‚Äôs an inspiring example of a high-quality implementation of a reinforcement learning algorithm : Powerful and useful application domains : Dialogue, Healthcare, Management, Robotics, Smart Grid, Supply Chains, etc. ‚Äú Self-Play is Automated Knowledge Creation. ‚Äú ‚Äî Carlos E. Perez References : OpenAI Gym by OpenAI OpenAI Baselines by OpenAI AlphaGo Zero: Learning from scratch by DeepMind A Visual Guide to Evolution Strategies by David Ha OpenAI Five by OpenAI 3. TensorFlow HubReusing Machine Learning Modules TensorFlow Hub is a library for the publication, discovery, and consumption of reusable parts of machine learning models. A module is a self-contained piece of a TensorFlow graph, along with its weights and assets, that can be reused across different tasks in a process known as transfer learning. Transfer learning can: Train a model with a smaller dataset ; Improve generalization: and Speed up training. ‚Äú I think transfer learning is the key to general intelligence. And I think the key to doing transfer learning will be the acquisition of conceptual knowledge that is abstracted away from perceptual details of where you learned it from. ‚Äú ‚Äî Demis Hassabis TensorFlow Hub Introducing TensorFlow Hub by Josh Gordon Transform your Web Site with an AI AgentFully-fledged AI systems can achieve serious revenue! Montr√©al Artificial Intelligence helps to transform Web sites for the age of artificial intelligence by developing machine learning agents in the browser that achieves goal-oriented behavior. Demos : Solving the cart-pole control problem in the browser using the policy-gradient method Live demo : https://storage.googleapis.com/tfjs-examples/cart-pole/dist/index.html Code : https://github.com/tensorflow/tfjs-examples/tree/master/cart-pole Predicting balls and strikes using TensorFlow.js Blog : https://medium.com/tensorflow/predicting-balls-and-strikes-using-tensorflow-js-2acf1d7a447c Animation with CPPNs and TensorFlow.js, an @observablehq notebook by Emily Reif @observablehq notebook by Emily Reif : https://beta.observablehq.com/@emilyreif/animation-with-cppns Move Mirror: An AI Experiment with Pose Estimation in the Browser using TensorFlow.js By Jane Friedhoff and Irene Alvarado : https://medium.com/tensorflow/move-mirror-an-ai-experiment-with-pose-estimation-in-the-browser-using-tensorflow-js-2f7b769f9b23 L1: Tensor Studio ‚Äî An in-browser live-programming environment by Milan Lajto≈° Live demo : https://mlajtos.github.io/L1/latest/ Github : https://github.com/mlajtos/L1 References : Unity ML-Agents Toolkit by Unity A Brief Survey of Deep Reinforcement Learning Arulkumaran et al. ‚Äú Nothing is more powerful than an idea whose time has come. ‚Äú ‚Äî Victor Hugo MontreÃÅal.AI is offering a new world age of impactful technical prowesses on an unprecedented scale. To order your AI Agent :‚úâÔ∏è Email Us : info@montreal.aiüìû Phone : +1.514.829.8269üåê Website : http://www.montreal.ai/üìù LinkedIn : https://www.linkedin.com/in/montrealai/üèõ Headquarters : 350, PRINCE-ARTHUR STREET W., SUITE #2105, MONTREAL [QC], CANADA, H2X 3R4 *Administrative Head Office #AIFirst #MontrealAI #MontrealArtificialIntelligence","link":"/MontrealAI.github.io/web-ai/index.html"},{"title":"MONTR√âAL.AI | Montr√©al Artificial Intelligence","text":"Montr√©al.AI AcademyARTIFICIAL INTELLIGENCE 101AI 101: For the Newcomers to Artificial Intelligence!On Tue, Nov 26, 2019 | 6:30 PM - 8:30 PM EST, the General Secretariat of MONTREAL.AI will present, with authority: ‚ÄúArtificial Intelligence 101: The First World-Class Overview of AI for the General Public‚Äú. Location: NRH Prince Arthur - Ballroom, 3625 Avenue du Parc, Montreal (Qu√©bec), Canada, H2X 3P8. Artificial Intelligence 101 : Buy Tickets on EventbriteBuy Tickets on Eventbrite var exampleCallback = function() { console.log('Order complete!'); }; window.EBWidgets.createWidget({ widgetType: 'checkout', eventId: '68213946751', modal: true, modalTriggerElementId: 'eventbrite-widget-modal-trigger-68213946751', onOrderComplete: exampleCallback }); ARTIFICIAL INTELLIGENCE 101: REGISTER ON EVENTBRITE AI 101: The First World-Class Overview of AI for All ‚ÄúThe best way to predict the future is to invent it.‚Äú ‚Äî Alan Kay var exampleCallback = function() { console.log('Order complete!'); }; window.EBWidgets.createWidget({ // Required widgetType: 'checkout', eventId: '68213946751', iframeContainerId: 'eventbrite-widget-container-68213946751', // Optional iframeContainerHeight: 425, // Widget height in pixels. Defaults to a minimum of 425px if not provided onOrderComplete: exampleCallback // Method called when an order has successfully completed }); A Well-Crafted Actionable 75 Minutes TutorialPOWERFUL &amp; USEFUL. This actionable tutorial is designed to entrust participants with the mindset, the skills and the tools to see AI from an empowering new vantage point by : exalting state of the art discoveries and science, curating the best open-source implementations and embodying the impetus that drives today‚Äôs artificial intelligence. ‚Äú(AI) will rank among our greatest technological achievements, and everyone deserves to play a role in shaping it.‚Äú ‚Äî Fei-Fei Li This AI 101 tutorial harnesses the fundamentals of artificial intelligence for the purpose of providing participants with powerful AI tools to learn, deploy and scale AI. AI opens up a world of new possibilities. Program overview: ‚ÄúPioneering an Impactful Understanding of AI‚Äù ‚ùñ Opening Address Session 0 ¬∑ Getting Started In the Cloud On a Local Machine Session 1 ¬∑ Deep Learning Neural Networks Convolution Neural Networks (CNNs) Recurrent Neural Networks (RNNs) Unsupervised Deep Learning (Self-Supervised Learning, Generative Adversarial Nets and Variational Autoencoders) Session 2 ¬∑ Autonomous Agents Evolution Strategies Deep Reinforcement Learning Self Play: A Quantum Leap Deep Meta-Learning Session 3 ¬∑ Environments OpenAI Gym DeepMind Lab Unity ML-Agents ‚ùñ Closing Remarks Keynote SpeakerKeynote: Vincent Boucher, Founding Chairman at MONTREAL.AI. In 1996, Vincent Boucher completed a B. Sc. Theoretical Physics in 1 (one) year, followed by a Master‚Äôs degree in Government Policy Analysis (1998) and a Master‚Äôs degree in Aerospace Engineering (Space Technology) (2000). From 2000 to 2002, he provided management consulting services for the Canadian Space Agency. In 2003, Vincent Boucher founded MONTREAL.AI | Montr√©al Artificial Intelligence. A Legendary History | How It All Began ‚Äî Learn the Source of an Exceptional Legacy : Vincent Boucher | ‚Ä¶ un cerveau de l‚Äôa√©rospatial! ‚Äî Le journal de Montreal Shooting Stars | Vincent Boucher ‚Äî The Canadian Space Agency Employee Newsletter Vincent Boucher | Un (jeune) homme d‚Äôexception ‚Äî Nathalie Petrowski, La Presse Tickets and Group ReservationGroup Reservation: : secretariat@montreal.ai Tickets: https://ai101montreal.eventbrite.ca Language: Tutorial given in English.Date And Time: Tue, 26 November 2019 | 6:30 PM ‚Äì 8:30 PM ESTLocation: NRH Prince Arthur - Ballroom, 3625 Avenue du Parc, Montreal (Qu√©bec), Canada, H2X 3P8. Tickets selling fast! THIS EVENT WILL SELL OUT. We are on the dawn of The Age of Artificial Intelligence. VIP AI 101 CheatSheet for AllFor the purpose of entrusting all sentient beings with powerful AI tools to learn, deploy and scale AI in order to enhance their prosperity, to settle planetary-scale problems and to inspire those who, with AI, will shape the 21st Century, Montr√©al.AI introduces the ‚ÄúVIP AI 101 CheatSheet for All‚Äù. VIP AI 101 CheatSheet for Allhttp://www.montreal.ai/ai4all.pdf Curated Open-Source Codes, Implementations and ScienceMONTREAL.AI is Preparing a Global Network of Education Centers to Pioneer an Impactful Understanding of AI and to Foster a Vector for Safe Humanitarian Artificial General Intelligence (AGI).Montr√©al.AI created the largest artificial intelligence community in Canada. Join us, learn and discuss at https://www.facebook.com/groups/MontrealAI/ ! You are qualified for a career in machine learning! Andrew NgI want to pursue machine learning as a career but not sure if I am qualified... 0. Getting StartedAI opens up a world of new possibilities. Today‚Äôs artificial intelligence is powerful, useful and accessible to all. Tinker with Neural Networks : Neural Network Playground ‚Äî TensorFlow In the Cloud Free GPU compute via Colab. Colab: An easy way to learn and use TensorFlow ‚Äî TensorFlow Six easy ways to run your Jupyter Notebook in the cloud ‚Äî Data School Practice Immediately ‚Äî Goku Mohandas On a Local Machine Install Anaconda and Launch ‚ÄòAnaconda Navigator‚Äô. Update Jupyterlab and Launch the Application. Under Notebook, Click on ‚ÄòPython 3‚Äô. In the Browser TensorFlow.js: a library for developing and training ML models in JavaScript. TensorFlow dev summit Official TensorFlow.js Launch Introducing TensorFlow.js: Machine Learning in Javascript ‚Äî Josh Gordon, Sara Robinson TensorFlow.js: Machine Learning for the Web and Beyond ‚Äî Daniel Smilkov, Nikhil Thorat, Yannick Assogba, Ann Yuan, Nick Kreeger, Ping Yu, Kangyi Zhang, Shanqing Cai, Eric Nielsen, David Soergel, Stan Bileschi, Michael Terry, Charles Nicholson, Sandeep N. Gupta, Sarah Sirajuddin, D. Sculley, Rajat Monga, Greg Corrado, Fernanda B. Viegas, Martin Wattenberg Datasets Making it easier to discover datasets. Preliminary Readings ‚ÄúWhen you first study a field, it seems like you have to memorize a zillion things. You don‚Äôt. What you need is to identify the 3-5 core principles that govern the field. The million things you thought you had to memorize are various combinations of the core principles.‚Äú ‚Äî J. Reed Deep Learning ‚Äî Yann LeCun, Yoshua Bengio, Geoffrey Hinton Papers With Code! | Over 950+ ML tasks, 500+ evaluation tables (including state of the art results) and 8500+ papers with code! ‚Äî Atlas ML Learn X in Y minutes (Where X=python3) ‚Äî Louie Dinh 6.S191: Introduction to Deep Learning | MIT‚Äôs official introductory course on deep learning methods and applications. ‚Äî Alexander Amini and Ava Soleimany Practical Deep Learning for Coders 2019 ‚Äî Jeremy Howard Foundations Built for a General Theory of Neural Networks ‚Äî Kevin Hartnett The Matrix Calculus You Need For Deep Learning ‚Äî Terence Parr, Jeremy Howard Introduction to the math of backprop ‚Äî Deb Panigrahi Introduction to Applied Linear Algebra ‚Äì Vectors, Matrices, and Least Squares ‚Äî Stephen Boyd and Lieven Vandenberghe, Cambridge University Press What are the limits of deep learning? ‚Äî M. Mitchell Waldrop ‚ÄúA birds-eye view of optimization algorithms‚Äù ‚Äî Fabian Pedregosa Using Nucleus and TensorFlow for DNA Sequencing Error Correction ‚Äî Gunjan Baid, Helen Li and Pi-Chuan Chang Dive into Deep Learning ‚Äî Aston Zhang, Zack C. Lipton, Mu Li, Alex J. Smola How to visualize decision trees ‚Äî Terence Parr, Prince Grover Machine Learning for Visualization ‚Äî Ian Johnson Seeing Theory: A visual introduction to probability and statistics. ‚Äî Daniel Kunin et al. explained.ai | Deep explanations of machine learning ‚Äî Terence Parr What is torch.nn really? ‚Äî Jeremy Howard Scipy Lecture Notes ‚Äî Scipy Deep Learning and Robotics ‚Äî Pieter Abbeel Natasha Jaques: ‚ÄúRecent advances in AI and machine learning‚Äù | Starsconf 2018 ‚Äî Natasha Jaques | Starsconf 2018 CS 188 | Introduction to Artificial Intelligence ‚Äî Pieter Abbeel, Dan Klein A Concise Handbook of TensorFlow ‚Äî Xihan Li The WIRED Guide to artificial intelligence ‚Äî WIRED How to teach yourself hard things ‚Äî Julia Evans UFLDL (Unsupervised Feature Learning and Deep Learning) Tutorial ‚Äî Andrew Ng, Jiquan Ngiam, Chuan Yu Foo, Yifan Mai, Caroline Suen Interview with The Youngest Kaggle Grandmaster: Mikel Bober-Irizar (anokas) ‚Äî Sanyam Bhutani, Hacker Noon Cutting-Edge Face Recognition is Complicated. These Spreadsheets Make it Easier. ‚Äî Dave Smith A radical new neural network design could overcome big challenges in AI ‚Äî Karen Hao Remarkable problem-solving ability of unicellular amoeboid organism and its mechanism ‚Äî Liping Zhu, Song-Ju Kim, Masahiko Hara, Masashi Aono Competitive Programmer‚Äôs Handbook ‚Äî Antti Laaksonen Machine Learning from scratch! ‚Äî Quan Tran Rules of Machine Learning: Best Practices for ML Engineering ‚Äî Martin Zinkevich A Neural Network in 11 lines of Python ‚Äî iamtrask ‚Äú1. Multiply things together 2. Add them up 3. Replaces negatives with zeros 4. Return to step 1, a hundred times.‚Äú ‚Äî Jeremy Howard How to build your own Neural Network from scratch in Python ‚Äî James Loy Deep Gaussian Processes ‚Äî Neil D. Lawrence Magic Sketchpad ‚Äî Monica Dinculescu AI Transformation Playbook ‚Äî Andrew Ng Understand TensorFlow by mimicking its API from scratch ‚Äî Dominic Elm Bias-Variance Decomposition ‚Äî Sebastian Raschka SpaceSheet: Interactive Latent Space Exploration through a Spreadsheet Interface Paper | Demo | Tool ‚Äî Bryan Loh, Tom White On intelligence: its creation and understanding ‚Äî Surya Ganguli NeurIPS 2018 Videos ‚Äî Thirty-second Conference on Neural Information Processing Systems Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks ‚Äî Adam Geitgey The Neural Aesthetic ‚Äî Gene Kogan MONet: Unsupervised Scene Decomposition and Representation ‚Äî Christopher P. Burgess, Loic Matthey, Nicholas Watters, Rishabh Kabra, Irina Higgins, Matt Botvinick, Alexander Lerchner Popular Machine Learning Algorithms Explained Project Jupyter | GitHub ‚Äî Oleksii Trekhleb Introduction to Artificial Intelligence, ULi√®ge, Fall 2018. ‚Äî Gilles Louppe Deep Learning cheatsheets for Stanford‚Äôs CS 230 ‚Äî Afshine Amidi, Shervine Amidi TensorFlow Blog ‚Äî TensorFlow Machine Learning From Scratch ‚Äî Erik Linder-Nor√©n A Beginner‚Äôs Guide to the Mathematics of Neural Networks ‚Äî A.C.C. Coolen An embedding is a mapping from discrete objects, such as words, to vectors of real numbers. 1. Deep LearningDeep learning allows computational models that are composed of multiple processing layers to learn REPRESENTATIONS of (raw) data with multiple levels of abstraction. At a high-level, neural networks are either encoders, decoders, or a combination of both. ‚ÄúDL is essentially a new style of programming‚Äì‚Äùdifferentiable programming‚Äù‚Äìand the field is trying to work out the reusable constructs in this style. We have some: convolution, pooling, LSTM, GAN, VAE, memory units, routing units, etc.‚Äú ‚Äî Thomas G. Dietterich 1.1 Neural Networks ‚ÄúNeural networks‚Äù are a sad misnomer. They‚Äôre neither neural nor even networks. They‚Äôre chains of differentiable, parameterized geometric functions, trained with gradient descent (with gradients obtained via the chain rule). A small set of highschool-level ideas put together.‚Äú ‚Äî Fran√ßois Chollet AI Playbook ‚Äî Andreessen Horowitz Clear Explanations of Machine Learning ‚Äî Distill Deep Learning Book ‚Äî Ian Goodfellow, Yoshua Bengio, Aaron Courville Neural Networks and Deep Learning ‚Äî Michael Nielsen Deep Learning ‚Äî Vincent Vanhoucke | Google A Complete Implementation of a Toy Neural Network ‚Äî Stanford CS class CS231n Neural networks: training with backpropagation ‚Äî Jeremy Jordan Introduction to Machine Learning for Coders ‚Äî Jeremy Howard Machine Learning Yearning ‚Äî Andrew Ng Effective TensorFlow for Non-Experts ‚Äî Google Developers Neural Network as Ordinary Differential Equations ‚Äî Kevin Gibson A curated collection of inspirational AI-powered JavaScript apps ‚Äî Elle Haproff, Asim Hussain, Osama Jandali Pytorch Implementation of Neural Processes ‚Äî Chris Ormandy A Few Unusual Autoencoders ‚Äî Colin Raffel Science of AI | How AI Training Scales ‚Äî OpenAI Pytorch implementation of JointVAE, a framework for disentangling continuous and discrete factors of variation ‚Äî Schlumberger Software Technology A New TensorFlow Hub Web Experience ‚Äî Andr√© Susano Pinto, Clemens Mewald Approximate Fisher Information Matrix to Characterise the Training of Deep Neural Networks ‚Äî Zhibin Liao, Tom Drummond, Ian Reid, Gustavo Carneiro Deep Learning on Graphs: A Survey ‚Äî Ziwei Zhang, Peng Cui, Wenwu Zhu TF Jam ‚Äî Shooting Hoops with Machine Learning ‚Äî Abe Haskins Building Web App for Computer Vision Model &amp; Deploying to Production in 10 Minutes*: A Detailed Guide ‚Äî Pankaj Mathur Measuring the Effects of Data Parallelism on Neural Network Training ‚Äî Christopher J. Shallue, Jaehoon Lee, Joe Antognini, Jascha Sohl-Dickstein, Roy Frostig, George E. Dahl Photo Wake-Up: 3D Character Animation from a Single Photo Paper | Project Page ‚Äî Chung-Yi Weng, Brian Curless, Ira Kemelmacher-Shlizerman Relational inductive biases, deep learning, and graph networks ‚Äî Peter W. Battaglia, Jessica B. Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, Caglar Gulcehre, Francis Song, Andrew Ballard, Justin Gilmer, George Dahl, Ashish Vaswani, Kelsey Allen, Charles Nash, Victoria Langston, Chris Dyer, Nicolas Heess, Daan Wierstra, Pushmeet Kohli, Matt Botvinick, Oriol Vinyals, Yujia Li, Razvan Pascanu Avito Demand Prediction Challenge : Kaggle winner explains how to combine categorical, numerical, image and text features into a single NN that gets you into top 10 without stacking ‚Äî Little Boat fast.ai | Making neural nets uncool again Intro Machine Learning | Practical Deep Learning | Cutting Edge Deep Learning | Computational Linear Algebra ‚Äî Jeremy Howard, Rachel Thomas | Fast.AI 1.1.1 Universal Approximation TheoremThe universal approximation theorem states that a feed-forward network with a single hidden layer containing a finite number of neurons can solve any given problem to arbitrarily close accuracy as long as you add enough parameters. Neural Networks + Gradient Descent + GPU: Infinitely flexible function: Neural Networks (multiple hidden layers: Deep Learning) ; All-purpose parameter fitting: Backpropagation ; and Fast and scalable: GPU. When a choice must be made, just feed the (raw) data to a deep neural network (universal function approximator). 1.2 Convolution Neural NetworkIn images, local combinations of edges form motifs, motifs assemble into parts, and parts form objects. The deep convolutional network, inspired by Hubel and Wiesel‚Äôs seminal work on early visual cortex, uses hierarchical layers of tiled convolutional filters to mimic the effects of receptive fields, thereby exploiting the local spatial correlations present in images. A ConvNet is made up of Layers. Every Layer has a simple API: It transforms an input 3D volume to an output 3D volume with some differentiable function that may or may not have parameters. ‚ÄúI admire the elegance of your method of computation; it must be nice to ride through these fields upon the horse of true mathematics while the like of us have to make our way laboriously on foot.‚Äú ‚Äî A. Einstein CNN Is All You Need ‚Äî Qiming Chen, Ren Wu Feature Visualization ‚Äî Chris Olah, Alexander Mordvintsev, Ludwig Schubert Explanatory Graphs for CNNs ‚Äî Quanshi Zhang, Xin Wang, Ruiming Cao, Ying Nian Wu, Feng Shi, Song-Chun Zhu Understanding Neural Networks Through Deep Visualization ‚Äî Jason Yosinski, Jeff Clune, Anh Nguyen, Thomas Fuchs, and Hod Lipson MedicalTorch ‚Äî Christian S. Perone How to visualize convolutional features in 40 lines of code ‚Äî Fabio M. Graetz Deep Learning for Generic Object Detection: A Survey ‚Äî Li Liu, Wanli Ouyang, Xiaogang Wang, Paul Fieguth, Jie Chen, Xinwang Liu, Matti Pietik√§inen A Unified Theory of Early Visual Representations from Retina to Cortex through Anatomically Constrained Deep CNNs ‚Äî Jack Lindsey, Samuel A. Ocko, Surya Ganguli, Stephane Deny The Building Blocks of Interpretability ‚Äî Chris Olah, Arvind Satyanarayan, Ian Johnson, Shan Carter, Ludwig Schubert, Katherine Ye, Alexander Mordvintsev Detectron : State-of-the-art Object Detection ‚Äî Ross Girshick and Ilija Radosavovic and Georgia Gkioxari and Piotr Doll\\‚Äô{a}r and Kaiming He YOLOv3: An Incremental Improvement | WebSite | YouTube ‚Äî Joseph Redmon, Ali Farhadi From Recognition to Cognition: Visual Commonsense Reasoning ‚Äî Rowan Zellers, Yonatan Bisk, Ali Farhadi, Yejin Choi AdVis.js : Exploring Fast Gradient Sign Method ‚Äî Jason Lin, Dilara Soylu Machine Learning for Artists | Demos Page | This is how convolution works ‚Äî Machine Learning for Artists Deep Painterly Harmonization | Notebook ‚Äî Sylvain Gugger A Deep Learning based magnifying glass ‚Äî Francesco Cardinale How Convolutional Neural Networks Work ‚Äî Brandon Rohrer TensorSpace: Neural network 3D visualization framework ‚ÄîTensorSpace 1.3 Recurrent Neural NetworksFor sequential inputs. Recurrent neural networks are networks with loops in them, allowing information to persist. RNNs process an input sequence one element at a time, maintaining in their hidden units a ‚Äòstate vector‚Äô that implicitly contains information about the history of all the past elements of the sequence. Long Short-Term Memory ‚Äî Sepp Hochreiter, J√ºrgen Schmidhuber Understanding LSTM Networks ‚Äî Christopher Olah Can Neural Networks Remember? ‚Äî Vishal Gupta Attention and Augmented RNN ‚Äî Olah &amp; Carter, 2016 Computer, respond to this email ‚Äî Post by Greg Corrado How do Mixture Density RNNs Predict the Future? ‚Äî Kai Olav Ellefsen, Charles Patrick Martin, Jim Torresen Reversible Recurrent Neural Networks ‚Äî Matthew MacKay, Paul Vicol, Jimmy Ba, Roger Grosse Recurrent Relational Networks Blog | arXiv | Code ‚Äî Rasmus Berg Palm, Ulrich Paquet, Ole Winther The Unreasonable Effectiveness of Recurrent Neural Networks ‚Äî Andrej Karpathy Massive Exploration of Neural Machine Translation Architectures arXiv | Docs | Code ‚Äî Denny Britz, Anna Goldie, Minh-Thang Luong, Quoc Le A TensorFlow implementation of : ‚ÄúHybrid computing using a neural network with dynamic external memory‚Äù GitHub ‚Äî Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka Grabska-Barwi≈Ñska, Sergio G√≥mez Colmenarejo, Edward Grefenstette, Tiago Ramalho, John Agapiou, Adri√† Puigdom√®nech Badia, Karl Moritz Hermann, Yori Zwols, Georg Ostrovski, Adam Cain, Helen King, Christopher Summerfield, Phil Blunsom, Koray Kavukcuoglu &amp; Demis Hassabis ‚ÄúI feel like a significant percentage of Deep Learning breakthroughs ask the question ‚Äúhow can I reuse weights in multiple places?‚Äù‚Äì Recurrent (LSTM) layers reuse for multiple timesteps‚Äì Convolutional layers reuse in multiple locations.‚Äì Capsules reuse across orientation.‚Äú ‚Äî Trask 1.4 Capsules Stacked Capsule Autoencoders ‚Äî Adam Kosiorek Dynamic Routing Between Capsules ‚Äî Sara Sabour, Nicholas Frosst, Geoffrey E Hinton Capsule Networks (CapsNets) ‚Äì Tutorial ‚Äî Aur√©lien G√©ron Understanding Hinton‚Äôs Capsule Networks. Part I: Intuition. ‚Äî Max Pechyonkin Capsules for Object Segmentation ‚Äî Rodney LaLonde, Ulas Bagci Brain Tumor Type Classification via Capsule Networks ‚Äî Parnian Afshar, Arash Mohammadi, Konstantinos N. Plataniotis A Tensorflow implementation of CapsNet ‚Äî Huadong Liao 1.5 Unsupervised LearningTrue intelligence will require independent learning strategies. Unsupervised learning is a paradigm for creating AI that learns without a particular task in mind: learning for the sake of learning. It captures some characteristics of the joint distribution of the observed random variables (learn the underlying structure). Self-supervised learning is derived form unsupervised learning where the data provides the supervision. 1.5.1 Generative Adversarial NetworkSimultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. $$\\min_{\\theta_g} \\max_{\\theta_d} [{\\rm IE_{x\\sim p_{data}(x)}} [log D_{\\theta_d}(x)] + {\\rm IE_{z\\sim p_z(z)}} [log(1 - D_{\\theta_d}(G_{\\theta_g}(z)))]]$$ ‚ÄúWhat I cannot create, I do not understand.‚Äú ‚Äî Richard Feynman This framework corresponds to a minimax two-player game. Generative Adversarial Nets ‚Äî Goodfellow et al. Generative Models ‚Äî OpenAI GAN Lab: Play with Generative Adversarial Networks (GANs) in your browser! ‚Äî Minsuk Kahng, Nikhil Thorat, Polo Chau, Fernanda Vi√©gas, Martin Wattenberg Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch) ‚Äî Dev Nag TensorFlow-GAN (TFGAN) ‚Äî TensorFlow Few-Shot Adversarial Learning of Realistic Neural Talking Head Models Wasserstein GAN GANSynth: Generate high-fidelity audio with GANs! SC-FEGAN: Face Editing Generative Adversarial Network CariGANs: Unpaired Photo-to-Caricature Translation GANpaint Paint with GAN units PyTorch pretrained BigGAN Neural scene representation and rendering ‚Äî S. M. Ali Eslami, Danilo J. Rezende, Frederic Besse, Fabio Viola, Ari S. Morcos, Marta Garnelo, Avraham Ruderman, Andrei A. Rusu, Ivo Danihelka, Karol Gregor, David P. Reichert, Lars Buesing, Theophane Weber, Oriol Vinyals, Dan Rosenbaum, Neil Rabinowitz, Helen King, Chloe Hillier, Matt Botvinick, Daan Wierstra, Koray Kavukcuoglu, Demis Hassabis Recycle-GAN: Unsupervised Video Retargeting Paper | Blog ‚Äî Aayush Bansal, Shugao Ma, Deva Ramanan, Yaser Sheikh On Self Modulation for Generative Adversarial Networks ‚Äî Ting Chen, Mario Lucic, Neil Houlsby, Sylvain Gelly Bayesian GAN arXiv | GitHub ‚Äî Yunus Saatchi, Andrew Gordon Wilson Adversarial Transfer Learning ‚Äî Garrett Wilson, Diane J. Cook Generating Memoji from Photos ‚Äî Pat Niemeyer GANPaint ‚Äî MIT-IBM Watson AI Lab The GAN Zoo ‚Äî Avinash Hindupur A collection of GANs TensorFlow | PyTorch StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks Paper | Code StyleGAN for art This Person Does Not Exist Which Person Is Real? This Resume Does Not Exist This Waifu Does Not Exist Encoder for Official TensorFlow Implementation How to recognize fake AI-generated images ‚Äî Kyle McDonald Demo of BigGAN in an official Colaboratory notebook (backed by a GPU) 1.5.2 Variational Auto-Encoders (VAEs)Variational Auto-Encoders (VAEs) are powerful models for learning low-dimensional representations. Debiasing Facial Detection Systems - Colab SpaceSheet: Interactive Latent Space Exploration with a Spreadsheet MusicVAE: Learning latent spaces for musical scores Slides: A Few Unusual Autoencoders Generative models in Tensorflow 2 Disentangled VAE‚Äôs (DeepMind 2016) ‚ÄúI think transfer learning is the key to general intelligence. And I think the key to doing transfer learning will be the acquisition of conceptual knowledge that is abstracted away from perceptual details of where you learned it from.‚Äú ‚Äî Demis Hassabis 2. Autonomous AgentsReinforcement learning (RL) studies how an agent can learn how to achieve goals in a complex, uncertain environment. An autonomous agent is any device that perceives its environment and takes actions that maximize its chance of success at some goal. At the bleeding edge of AI, autonomous agents can learn from experience, simulate worlds and orchestrate meta-solutions. Here‚Äôs an informal definition of the universal intelligence of agent `\\pi` $$\\Upsilon(\\pi) := \\sum\\limits_{\\mu \\in E} 2^{-K(\\mu)} V^{\\pi}_{\\mu}$$ ‚ÄúIntelligence measures an agent‚Äôs ability to achieve goals in a wide range of environments.‚Äú ‚Äî Shane Legg 2.1 Evolution Strategies ‚ÄúEvolution is a slow learning algorithm that with the sufficient amount of compute produces a human brain.‚Äú ‚Äî Wojciech Zaremba Evolution and neural networks proved a potent combination in nature. Natural evolutionary strategy directly evolves the weights of a DNN and performs competitively with the best deep reinforcement learning algorithms. Neuroevolution enables capabilities that are typically unavailable to gradient-based approaches. A Visual Guide to Evolution Strategies ‚Äî David Ha Evolution Strategies as a Scalable Alternative to Reinforcement Learning ‚Äî OpenAI The Surprising Creativity of Digital Evolution: A Collection of Anecdotes from the Evolutionary Computation and Artificial Life Research Communities ‚Äî Joel Lehman, Jeff Clune, Dusan Misevic, Christoph Adami, Lee Altenberg, Julie Beaulieu, Peter J. Bentley, Samuel Bernard, Guillaume Beslon, David M. Bryson, Patryk Chrabaszcz, Nick Cheney, Antoine Cully, Stephane Doncieux, Fred C. Dyer, Kai Olav Ellefsen, Robert Feldt, Stephan Fischer, Stephanie Forrest, Antoine Fr√©noy, Christian Gagn√©, Leni Le Goff, Laura M. Grabowski, Babak Hodjat, Frank Hutter, Laurent Keller, Carole Knibbe, Peter Krcah, Richard E. Lenski, Hod Lipson, Robert MacCurdy, Carlos Maestre, Risto Miikkulainen, Sara Mitri, David E. Moriarty, Jean-Baptiste Mouret, Anh Nguyen, Charles Ofria, Marc Parizeau, David Parsons, Robert T. Pennock, William F. Punch, Thomas S. Ray, Marc Schoenauer, Eric Shulte, Karl Sims, Kenneth O. Stanley, Fran√ßois Taddei, Danesh Tarapore, et al. (4 additional authors not shown) Evolving Neural Networks ‚Äî Risto Miikkulainen Recombination of Artificial Neural Networks ‚Äî Aaron Vose, Jacob Balma, Alex Heye, Alessandro Rigazzi, Charles Siegel, Diana Moise, Benjamin Robbins, Rangan Sukumar Nevergrad: An open source tool for derivative-free optimization ‚Äî J. Rapin and O. Teytaud Evolved Policy Gradients ‚Äî Rein Houthooft, Richard Y. Chen, Phillip Isola, Bradly C. Stadie, Filip Wolski, Jonathan Ho, Pieter Abbeel Using Evolutionary AutoML to Discover Neural Network Architectures ‚Äî Google AI Neural architecture search has advanced to the point where it can outperform human-designed models. ‚Äú‚Ä¶ evolution ‚Äî whether biological or computational ‚Äî is inherently creative, and should routinely be expected to surprise, delight, and even outwit us.‚Äú ‚Äî The Surprising Creativity of Digital Evolution, Lehman et al. 2.2 Deep Reinforcement LearningIn reinforcement learning, an agent interacts with an environment through a Markov decision process. The goal in reinforcement learning is to train the agent to maximize the sum of future rewards, called the return. Reinforcement Learning: An Introduction ‚Äî Andrew Barto and Richard S. Sutton Spinning Up as a Deep RL Researcher ‚Äî Joshua Achiam Intuitive RL: Intro to Advantage-Actor-Critic (A2C) ‚Äî Rudy Gilman Simple Beginner‚Äôs guide to Reinforcement Learning &amp; its implementation ‚Äî Faizan Shaikh Spinning Up in Deep RL ‚Äî Joshua Achiam AlphaStar: Mastering the Real-Time Strategy Game StarCraft II ‚Äî Oriol Vinyals, Igor Babuschkin, Junyoung Chung, Michael Mathieu, Max Jaderberg, Wojtek Czarnecki, Andrew Dudzik, Aja Huang, Petko Georgiev, Richard Powell, Timo Ewalds, Dan Horgan, Manuel Kroiss, Ivo Danihelka, John Agapiou, Junhyuk Oh, Valentin Dalibard, David Choi, Laurent Sifre, Yury Sulsky, Sasha Vezhnevets, James Molloy, Trevor Cai, David Budden, Tom Paine, Caglar Gulcehre, Ziyu Wang, Tobias Pfaff, Toby Pohlen, Dani Yogatama, Julia Cohen, Katrina McKinney, Oliver Smith, Tom Schaul, Timothy Lillicrap, Chris Apps, Koray Kavukcuoglu, Demis Hassabis, David Silver Creating a Zoo of Atari-Playing Agents to Catalyze the Understanding of Deep Reinforcement Learning ‚Äî Felipe Petroski Such, Vashisht Madhavan, Rosanne Liu, Rui Wang, Yulun Li, Jeff Clune, Joel Lehman An Introduction to Deep Reinforcement Learning ‚Äî Vincent Francois-Lavet, Peter Henderson, Riashat Islam, Marc G. Bellemare, Joelle Pineau Welcome to Spinning Up in Deep RL! ‚Äî OpenAI A (Long) Peek into Reinforcement Learning ‚Äî Lilian Weng A Theoretical Analysis of Deep Q-Learning ‚Äî Zhuora Yang, Yuchen Xie, Zhaoran Wang Monte Carlo Tree Search ‚Äì beginners guide ‚Äî Kamil Czarnog√≥rski Quantifying Generalization in Reinforcement Learning ‚Äî OpenAI Relational Deep Reinforcement Learning ‚Äî Vinicius Zambaldi, David Raposo, Adam Santoro, Victor Bapst, Yujia Li, Igor Babuschkin, Karl Tuyls, David Reichert, Timothy Lillicrap, Edward Lockhart, Murray Shanahan, Victoria Langston, Razvan Pascanu, Matthew Botvinick, Oriol Vinyals, Peter Battaglia Getting Started With MarathonEnvs v0.5.0a ‚Äî Joe Booth AlphaZero: Shedding new light on the grand games of chess, shogi and Go ‚Äî David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, Timothy Lillicrap, Karen Simonyan, Demis Hassabis DQN Adventure: from Zero to State of the Art ‚Äî higgsfield SURREAL: Open-Source Reinforcement Learning Framework and Robot Manipulation Benchmark ‚Äî Linxi Fan, Yuke Zhu, Jiren Zhu, Zihua Liu, Anchit Gupta, Joan Creus-Costa, Silvio Savarese, Li Fei-Fei Learning to Act by Predicting the Future ‚Äî Alexey Dosovitskiy, Vladlen Koltun AlphaFold: Using AI for scientific discovery ‚Äî Andrew Senior, John Jumper, Demis Hassabis POET: Endlessly Generating Increasingly Complex and Diverse Learning Environments and their Solutions through the Paired Open-Ended Trailblazer ‚Äî Rui Wang, Joel Lehman, Jeff Clune, Kenneth O. Stanley Reinforcement Learning with Prediction-Based Rewards ‚Äî Yura Burda, Harri Edwards, OpenAI Playing hard exploration games by watching YouTube Paper | YouTube ‚Äî Yusuf Aytar, Tobias Pfaff, David Budden, Tom Le Paine, Ziyu Wang, Nando de Freitas Exploration by Random Network Distillation Paper | Code ‚Äî Yuri Burda, Harrison Edwards, Amos Storkey, Oleg Klimov Large-Scale Study of Curiosity-Driven Learning Paper | Code ‚Äî Yuri Burda, Harri Edwards, Deepak Pathak, Amos Storkey, Trevor Darrell, Alexei A. Efros OpenAI Baselines : A2C | ACER | ACKTR | DDPG | DQN | GAIL | HER | PPO2 | TRPO ‚Äî OpenAI Stable Baselines is a set of improved implementations of Reinforcement Learning (RL) algorithms based on OpenAI Baselines Docs | Blog | Code ‚Äî Antonin Raffin TRPO-GAE Blog | arXiv | arXiv ‚Äî OpenAI Improvised Robotic Design with Found Objects ‚Äî Azumi Maekawa, Ayaka Kume, Hironori Yoshida, Jun Hatori, Jason Naradowsky, Shunta Saito A3C arXiv | Medium | Code ‚Äî OpenAI Deep Reinforcement Learning ‚Äî Sergey Levine Vel: PyTorch meets baselines ‚Äî Jerry Continual Match Based Training in Pommerman: Technical Report ‚Äî Peng Peng, Liang Pang, Yufeng Yuan, Chao Gao Actor-Critic Policy Optimization in Partially Observable Multiagent Environments ‚Äî Sriram Srinivasan, Marc Lanctot, Vinicius Zambaldi, Julien Perolat, Karl Tuyls, Remi Munos, Michael Bowling TensorFlow Reinforcement Learning ‚Äî DeepMind TensorFlow Agents ‚Äî TensorFlow TensorFlow.js Implementation of DeepMind‚Äôs AlphaZero Algorithm for Chess Live Demo | Code ‚Äî Fran√ßois Pays DiCE: The Infinitely Differentiable Monte Carlo Estimator ‚Äî Vitaly Kurin, Jakob Foerster, Shimon Whiteson TorchCraftAI: A bot platform for machine learning research on StarCraft¬Æ: Brood War¬Æ ‚Äî Facebook Curiosity and Procrastination in Reinforcement Learning ‚Äî Nikolay Savinov, Timothy Lillicrap Hierarchical Actor-Critic ‚Äî Andrew Levy, Robert Platt, Kate Saenko Montezuma‚Äôs Revenge Solved by Go-Explore, a New Algorithm for Hard-Exploration Problems ‚Äî Adrien Ecoffet, Joost Huizinga, Joel Lehman, Kenneth O. Stanley, Jeff Clune Computational Theories of Curiosity-Driven Learning ‚Äî Pierre-Yves Oudeyer Depth-Limited Solving for Imperfect-Information Games ‚Äî Noam Brown, Tuomas Sandholm, Brandon Amos Optimizing Expectations: From Deep Reinforcement Learning to Stochastic Computation Graphs ‚Äî John Schulman Neural Episodic Control ‚Äî Alexander Pritzel, Benigno Uria, Sriram Srinivasan, Adri√† Puigdom√®nech, Oriol Vinyals, Demis Hassabis, Daan Wierstra, Charles Blundell RLlib: Abstractions for Distributed Reinforcement Learning ‚Äî Eric Liang, Richard Liaw, Philipp Moritz, Robert Nishihara, Roy Fox, Ken Goldberg, Joseph E. Gonzalez, Michael I. Jordan, Ion Stoica TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep Reinforcement Learning ‚Äî Gregory Farquhar, Tim Rockt√§schel, Maximilian Igl, Shimon Whiteson Q-map: a Convolutional Approach for Goal-Oriented Reinforcement Learning ‚Äî Fabio Pardo, Vitaly Levdik, Petar Kormushev Learning to Search with MCTSnets ‚Äî Arthur Guez, Th√©ophane Weber, Ioannis Antonoglou, Karen Simonyan, Oriol Vinyals, Daan Wierstra, R√©mi Munos, David Silver Convergence of Value Aggregation for Imitation Learning ‚Äî Ching-An Cheng, Byron Boots Dopamine : DQN | C51 | Rainbow | Implicit Quantile Network ‚Äî Marc G. Bellemare, Pablo Samuel Castro, Carles Gelada, Saurabh Kumar, Subhodeep Moitra S-RL Toolbox: Reinforcement Learning (RL) and State Representation Learning (SRL) for Robotics ‚Äî Antonin RAFFIN Advanced Deep Learning and Reinforcement Learning ‚Äî DeepMind Researchers Reinforcement Learning for Improving Agent Design arXiv | Blog ‚Äî David Ha Deep Reinforcement Learning from Human Preferences arXiv | Blog | Code ‚Äî OpenAI Introduction to Learning to Trade with Reinforcement Learning ‚Äî Denny Britz Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience ‚Äî Yevgen Chebotar, Ankur Handa, Viktor Makoviychuk, Miles Macklin, Jan Issac, Nathan Ratliff, Dieter Fox Robustness via Retrying: Closed-Loop Robotic Manipulation with Self-Supervised Learning ‚Äî Frederik Ebert, Sudeep Dasari, Alex X. Lee, Sergey Levine, Chelsea Finn CURIOUS: Intrinsically Motivated Multi-Task, Multi-Goal Reinforcement Learning ‚Äî C√©dric Colas, Olivier Sigaud, Pierre-Yves Oudeyer Bayesian Optimization in AlphaGo ‚Äî Yutian Chen, Aja Huang, Ziyu Wang, Ioannis Antonoglou, Julian Schrittwieser, David Silver, Nando de Freitas One-Shot High-Fidelity Imitation: Training Large-Scale Deep Nets with RL ‚Äî Tom Le Paine, Sergio G√≥mez Colmenarejo, Ziyu Wang, Scott Reed, Yusuf Aytar, Tobias Pfaff, Matt W. Hoffman, Gabriel Barth-Maron, Serkan Cabi, David Budden, Nando de Freitas Optimizing Agent Behavior over Long Time Scales by Transporting Value ‚Äî Chia-Chun Hung, Timothy Lillicrap, Josh Abramson, Yan Wu, Mehdi Mirza, Federico Carnevale, Arun Ahuja, Greg Wayne Large-Scale Study of Curiosity-Driven Learning ‚Äî Yuri Burda, Harri Edwards, Deepak Pathak, Amos Storkey, Trevor Darrell, Alexei A. Efros Learning to Dress: Synthesizing Human Dressing Motion via Deep Reinforcement Learning ‚Äî Alexander Clegg, Wenhao Yu, Jie Tan, C. Karen Liu, Greg Turk, SIGGRAPH Asia 2018 Automatic Poetry Generation with Mutual Reinforcement Learning ‚Äî Xiaoyuan Yi, Maosong Sun, Ruoyu Li, Wenhao Li Learning to Communicate with Deep Multi-Agent Reinforcement Learning in PyTorch ‚Äî Minqi Jiang Learning to Navigate the Web ‚Äî Anonymous Understanding &amp; Generalizing AlphaGo Zero ‚Äî Anonymous Deep RL Bootcamp ‚Äî Pieter Abbeel, Yan (Rocky) Duan, Xi (Peter) Chen, Andrej Karpathy 2.2.1 Model-Based RLIn Model-Based RL, the agent generates predictions about the next state and reward before choosing each action. World Models ‚Äî David Ha, J√ºrgen Schmidhuber Imagination-Augmented Agents for Deep Reinforcement Learning ‚Äî Th√©ophane Weber, S√©bastien Racani√®re, David P. Reichert, Lars Buesing, Arthur Guez, Danilo Jimenez Rezende, Adria Puigdom√®nech Badia, Oriol Vinyals, Nicolas Heess, Yujia Li, Razvan Pascanu, Peter Battaglia, Demis Hassabis, David Silver, Daan Wierstra Learning Latent Dynamics for Planning from Pixels ‚Äî Hafner et al. Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm (AlphaZero) ‚Äî Silver et al. ‚ÄúNo superintelligent AI is going to bother with a task that is harder than hacking its reward function.‚Äú ‚Äî The Lebowski theorem 2.3 Self PlaySelf-play mirrors similar insights from coevolution. AlphaGo Zero showed that algorithms matter much more than big data and massive amounts of computation: ‚ÄúSelf-Play is Automated Knowledge Creation.‚Äú ‚Äî Carlos E. Perez Transfer learning is the key to go from self-play to the real world. Explaining AlphaGo: Interpreting Contextual Effects in Neural Networks ‚Äî Zenan Ling, Haotian Ma, Yu Yang, Robert C. Qiu, Song-Chun Zhu, Quanshi Zhang Deep Learning: AlphaGo Zero Explained In One Picture ‚Äî L.V. How to build your own AlphaZero AI using Python and Keras ‚Äî David Foster An open-source implementation of the AlphaGoZero algorithm ‚Äî TensorFlow ELF OpenGo: An Open Reimplementation of AlphaZero ‚Äî Tian et al. TensorFlow.js Implementation of DeepMind‚Äôs AlphaZero Algorithm for Chess. Live Demo | Code ‚Äî Fran√ßois Pays 2.4 Multi-Agent Populations Machine Theory of Mind ‚Äî Rabinowitz et al. A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning ‚Äî Lanctot et al. Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments ‚Äî Al-Shedivat et al. Intrinsic Social Motivation via Causal Influence in Multi-Agent RL ‚Äî Natasha Jaques, Angeliki Lazaridou, Edward Hughes, Caglar Gulcehre, Pedro A. Ortega, DJ Strouse, Joel Z. Leibo, Nando de Freitas Autonomous Agents Modelling Other Agents: A Comprehensive Survey and Open Problems ‚Äî Stefano V. Albrecht, Peter Stone Learning with Opponent-Learning Awareness Paper | Blog ‚Äî OpenAI GPU-Accelerated Robotic Simulation for Distributed Reinforcement Learning Paper | Blog ‚Äî Jacky Liang, Viktor Makoviychuk, Ankur Handa, Nuttapong Chentanez, Miles Macklin, Dieter Fox, NVIDIA Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments Paper | Blog | Code ‚Äî OpenAI 2.5 Deep Meta-LearningLearning to Learn. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. A meta-learning algorithm takes in a distribution of tasks, where each task is a learning problem, and it produces a quick learner ‚Äî a learner that can generalize from a small number of examples. Learning to Learn Paper | Code ‚Äî Google DeepMind, University of Oxford, Canadian Institute for Advanced Research Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks ‚Äî Chelsea Finn, Pieter Abbeel, Sergey Levine AutoML: Methods, Systems, Challenges ‚Äî Frank Hutter, Lars Kotthoff, Joaquin Vanschoren Causal Reasoning from Meta-reinforcement Learning ‚Äî Ishita Dasgupta, Jane Wang, Silvia Chiappa, Jovana Mitrovic, Pedro Ortega, David Raposo, Edward Hughes, Peter Battaglia, Matthew Botvinick, Zeb Kurth-Nelson The Evolved Transformer ‚Äî David R. So, Chen Liang, Quoc V. Le Talos: Hyperparameter Scanning and Optimization for Keras ‚Äî Autonomio EAT-NAS: Elastic Architecture Transfer for Accelerating Large-scale Neural Architecture Search ‚Äî Jiemin Fang, Yukang Chen, Xinbang Zhang, Qian Zhang, Chang Huang, Gaofeng Meng, Wenyu Liu, Xinggang Wang FIGR: Few-shot Image Generation with Reptile ‚Äî Louis Clou√¢tre, Marc Demers Efficient Neural Architecture Search via Parameter Sharing Paper | Code ‚Äî Hieu Pham, Melody Y. Guan, Barret Zoph, Quoc V. Le, Jeff Dean Meta-Learning Shared Hierarchies Paper | Blog | Code ‚Äî OpenAI Learning Unsupervised Learning Rules ‚Äî Luke Metz, Niru Maheswaranathan, Brian Cheung, Jascha Sohl-Dickstein Reptile: A Scalable Meta-Learning Algorithm ‚Äî Alex Nichol, John Schulman Learning Shared Dynamics with Meta-World Models ‚Äî Lisheng Wu, Minne Li, Jun Wang NIPS2017 Meta Learning Symposium videos ‚Äî NIPS 2017 Colaboratory reimplementation of MAML in TF 2.0 ‚Äî Marianne Linhares Monteiro ‚ÄúThe notion of a neural ‚Äúarchitecture‚Äù is going to disappear thanks to meta learning.‚Äú ‚Äî Andrew Trask 3. Environments3.1 OpenAI Gym OpenAI Gym WebSite | Blog | GitHub | White Paper ‚Äî OpenAI 3.2 Unity ML-Agents Unity ML-Agents WebSite | GitHub | Documentation | Challenge I ‚Äî Unity Technologies Puppo, The Corgi: Cuteness Overload with the Unity ML-Agents Toolkit ‚Äî Vincent-Pierre Berges, Leon Chen 3.3 DeepMind Control Suite DeepMind Control Suite Paper | GitHub | Video ‚Äî DeepMind 3.4 Brigham Young University | Holodeck BYU Holodeck: A high-fidelity simulator for deep reinforcement learning Website | GitHub | Documentation ‚Äî Brigham Young University 3.5 Facebook‚Äôs Horizon Horizon: Facebook‚Äôs Open Source Applied Reinforcement Learning Platform Paper | GitHub | Blog ‚Äî Jason Gauci, Edoardo Conti, Yitao Liang, Kittipat Virochsiri, Yuchen He, Zachary Kaden, Vivek Narayanan, Xiaohui Ye 3.6 PhysX PhysX SDK, an Open-Source Physics Engine GitHub | Blog ‚Äî NVIDIA 4. General Readings, Ressources and Tools Building safe artificial intelligence: specification, robustness, and assurance ‚Äî Pedro A. Ortega, Vishal Maini, and the DeepMind safety team Google Dataset Search Beta ‚Äî Google Papers with Code ‚Äî Papers with Code GitXiv | arXiv + CODE ‚Äî Collaborative Open Computer Science Best Paper Awards in Computer Science (since 1996) ‚Äî Jeff Huang The Vulnerable World Hypothesis ‚Äî Nick Bostrom Podcast: Existential Hope in 2019 and Beyond ‚Äî Ariel Conn Scalable agent alignment via reward modeling Medium | arXiv ‚Äî Jan Leike, David Krueger, Tom Everitt, Miljan Martic, Vishal Maini, Shane Legg The 2018 AI Index report ‚Äî Yoav Shoham, Raymond Perrault, Erik Brynjolfsson, Jack Clark, James Manyika, Juan Carlos Niebles, Terah Lyons, John Etchemendy, Barbara Grosz, Zoe Bauer ASILOMAR AI PRINCIPLES ‚Äî The 2017 Asilomar conference Strategic Implications of Openness in AI Development ‚Äî Nick Bostrom ‚ÄúI believe that the answer here is to figure out how to create superintelligent A.I. such that even if ‚Äì when ‚Äì it escapes, it is still safe because it is fundamentally on our side because it shares our values. I see no way around this difficult problem.‚Äú ‚Äî Nick Bostrom Artificial Intelligence and Human Rights ‚Äî Jessica Fjeld, Hannah Hilligoss, Nele Achten, Maia Levy Daniel, Sally Kagay, and Joshua Feldman (Visualization Designed By: Arushi Singh) teleportHQ ThinkToCode ecosystem ‚Äî teleportHQ Statistical physics of liquid brains ‚Äî Jordi Pinero and Ricard Sole Reframing Superintelligence ‚Äî K. Eric Drexler Interpretable Machine Learning ‚Äî Christoph Molnar Building a Winning Self-Driving Car in Six Months ‚Äî Keenan Burnett, Andreas Schimpe, Sepehr Samavi, Mona Gridseth, Chengzhi Winston Liu, Qiyang Li, Zachary Kroeze, Angela P. Schoellig Une intelligence artificielle bien r√©elle : les termes de l‚ÄôIA ‚Äî Office qu√©b√©cois de la langue fran√ßaise How to deliver on Machine Learning projects ‚Äî Emmanuel Ameisen The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation ‚Äî Miles Brundage, Shahar Avin, Jack Clark, Helen Toner, Peter Eckersley, Ben Garfinkel, Allan Dafoe, Paul Scharre, Thomas Zeitzoff, Bobby Filar, Hyrum Anderson, Heather Roff, Gregory C. Allen, Jacob Steinhardt, Carrick Flynn, Se√°n √ì h√âigeartaigh, Simon Beard, Haydn Belfield, Sebastian Farquhar, Clare Lyle, Rebecca Crootof, Owain Evans, Michael Page, Joanna Bryson, Roman Yampolskiy, Dario Amodei Machine Learning for Combinatorial Optimization: a Methodological Tour d‚ÄôHorizon ‚Äî Yoshua Bengio, Andrea Lodi, Antoine Prouvost 26-Year-Old Nigerian Creates First Gaming Robot ‚Äî Christina Santi Machine Learning Top 10 Articles for the Past Month (v.Oct 2018) ‚Äî Mybridge Is artificial intelligence set to become art‚Äôs next medium? ‚Äî Jonathan Bastable, Christie‚Äôs Phrase-Based &amp; Neural Unsupervised Machine Translation arXiv | Code | Blog ‚Äî Guillaume Lample, Myle Ott, Alexis Conneau, Ludovic Denoyer, Marc‚ÄôAurelio Ranzato Tensor Considered Harmful ‚Äî Alexander Rush An Artificial Neuron Implemented on an Actual Quantum Processor ‚Äî Tacchino et al. Efficiently measuring a quantum device using machine learning ‚Äî D.T. Lennon, H. Moon, L.C. Camenzind, Liuqi Yu, D.M. Zumb√ºhl, G.A.D. Briggs, M.A. Osborne, E.A. Laird, N. Ares Deep Learning : Current Limits and What Lies Beyond Them ‚Äî Fran√ßois Chollet Open-ended Learning in Symmetric Zero-sum Games ‚Äî David Balduzzi, Marta Garnelo, Yoram Bachrach, Wojtek Czarnecki, Julien Perolat, Max Jaderberg, Thore Graepel Poker | Solving Imperfect-Information Games via Discounted Regret Minimization ‚Äî Noam Brown, Tuomas Sandholm Automatically Generating Comments for Arbitrary Source Code) ‚Äî Jessica Moore The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning) ‚Äî Jay Alammar 10 Exciting Ideas of 2018 in NLP ‚Äî Sebastian Ruder Deconstructing BERT: Distilling 6 Patterns from 100 Million Parameters ‚Äî Jesse Vig Learning to Infer Graphics Programs from Hand-Drawn Images ‚Äî Kevin Ellis, Daniel Ritchie, Armando Solar-Lezama, Joshua B. Tenenbaum TensorFlow code and pre-trained models for BERT (Bidirectional Encoder Representations from Transformers) ‚Äî Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova The Superintelligent Will: Motivation and Instrumental Rationality in Advanced Artificial Agents ‚Äî Nick Bostrom MobiLimb: Augmenting Mobile Devices with a Robotic Limb ‚Äî Marc Teyssier, Gilles Bailly, Catherine Pelachaud, Eric Lecolinet 32-Legged Spherical Robot Moves Like an Amoeba ‚Äî Evan Ackerman, IEEE Spectrum On winning all the big academic recent competitions. Presentation. ‚Äî Megvii (Face++) Team Stanford AI recreates chemistry‚Äôs periodic table of elements ‚Äî Ker Than Neural Approaches to Conversational AI ‚Äî Jianfeng Gao, Michel Galley, Lihong Li Learned optimizers that outperform SGD on wall-clock and validation loss ‚Äî Luke Metz, Niru Maheswaranathan, Jeremy Nixon, C. Daniel Freeman, Jascha Sohl-Dickstein Beauty and the Beast: Optimal Methods Meet Learning for Drone Racing ‚Äî Elia Kaufmann, Mathias Gehrig, Philipp Foehn, Ren√© Ranftl, Alexey Dosovitskiy, Vladlen Koltun, Davide Scaramuzza Writing Code for NLP Research ‚Äî Allen Institute for Artificial Intelligence Autonomous Tidying-up Robot System ‚Äî Preferred Networks Emerging Technology and Ethics Research Guide ‚Äì v 1.0 ‚Äî Danya Glabau Machine learning and artificial intelligence in the quantum domain ‚Äî Vedran Dunjko, Hans J. Briegel Playing Mortal Kombat with TensorFlow.js. Transfer learning and data augmentation ‚Äî Minko Gechev A series on quantum computing? Welcome to QuantumCasts! ‚Äî Marissa Giustina NLP.js : a general natural language utilities for nodejs ‚Äî AXA Shared Services Spain S.A. Hierarchical Multi-Task Learning model: One NLP model to rule them all! Medium | Demo | Code ‚Äî Hugging Face Constructing exact representations of quantum many-body systems with deep neural networks ‚Äî Giuseppe Carleo Over 200 of the Best Machine Learning, NLP, and Python Tutorials ‚Äî 2018 Edition ‚Äî Robbie Allen Deep Learning Papers Reading Roadmap ‚Äî Flood Sung Learn Machine Learning from Top 50 Articles for the Past Year (v.2019) ‚Äî Mybridge Open Courses and Textbooks ‚Äî Samuel G. Finlayson ~250 awesome short lectures on robotics ‚Äî Queensland University of Technology Robot Academy The Best Textbooks on Every Subject ‚Äî lukeprog ‚ÄúML paper writing pro-tip: you can download the raw source of any arxiv paper. Click on the ‚ÄúOther formats‚Äù link, then click ‚ÄúDownload source‚Äù. This gets you a .tar.gz with all the .tex files, all the image files for the figures in their original resolution, etc.‚Äú ‚Äî Ian Goodfellow Artificial Intelligence 101 : Buy Tickets on EventbriteBuy Tickets on Eventbrite var exampleCallback = function() { console.log('Order complete!'); }; window.EBWidgets.createWidget({ widgetType: 'checkout', eventId: '68213946751', modal: true, modalTriggerElementId: 'eventbrite-widget-modal-trigger-68213946751', onOrderComplete: exampleCallback }); ARTIFICIAL INTELLIGENCE 101: REGISTER ON EVENTBRITE !function(f,b,e,v,n,t,s) {if(f.fbq)return;n=f.fbq=function(){n.callMethod? n.callMethod.apply(n,arguments):n.queue.push(arguments)}; if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version=‚Äô2.0‚Äô; n.queue=[];t=b.createElement(e);t.async=!0; t.src=v;s=b.getElementsByTagName(e)[0]; s.parentNode.insertBefore(t,s)}(window, document,‚Äôscript‚Äô, ‚Äòhttps://connect.facebook.net/en_US/fbevents.js&#39;); fbq(‚Äòinit‚Äô, ‚Äò587955031642222‚Äô); fbq(‚Äòtrack‚Äô, ‚ÄòPageView‚Äô); Group Reservation : ‚úâÔ∏è Email Us : info@montreal.aiüìû Phone : +1.514.829.8269üåê Website : http://www.montreal.aiüìù LinkedIn : https://www.linkedin.com/in/montrealaiüèõ Headquarters : 350, PRINCE-ARTHUR STREET W., SUITE #2105, MONTREAL [QC], CANADA, H2X 3R4 *Administrative Head Office #AIFirst #ArtificialIntelligence101 #MontrealAI #MontrealAIAcademy #MontrealArtificialIntelligence","link":"/MontrealAI.github.io/academy/index.html"},{"title":"MONTR√âAL.AI | Montr√©al Artificial Intelligence","text":"MONTR√âAL.AI SPACEA New Era of Superhuman Scientific Discoveries. ‚ÄúMy goal is simple. It is a complete understanding of the universe, why it is as it is and why it exists at all.‚Äú ‚Äî Stephen Hawking A Legendary History | How It All Began ‚Äî Learn the source of an exceptional legacy : Vincent Boucher | ‚Ä¶ un cerveau de l‚Äôa√©rospatial! ‚Äî Le journal de Montreal Shooting Stars | Vincent Boucher ‚Äî The Canadian Space Agency Employee Newsletter Vincent Boucher | Un (jeune) homme d‚Äôexception ‚Äî Nathalie Petrowski, La Presse Montr√©al.AI Space : Premium VisionAI + Aerospace | Physics | Robotics Premium Vision : To be the keystone of the AI Space industry. ‚ÄúRecognizing that Montreal is a world-class aerospace industry hub and a world leader in artificial intelligence, we‚Äôve created Montr√©al.AI Space.‚Äú ‚Äî Vincent Boucher, B. Sc. Physics, M. A. Policy Analysis and M. Sc. Aerospace Engineering (Space Technology), Founding Chairman at Montr√©al.AI Montr√©al.AI Space has a Jewel status in the Montr√©al.AI Portfolio. ‚ÄúWhat I cannot create, I do not understand.‚Äú ‚Äî Richard Feynman Montr√©al.AI Space : Solving Humanity‚Äôs Toughest ChallengesWe are at the verge of a global technological shift. Montr√©al.AI Space leverages aerospace engineering, applied artificial intelligence and space science researches for use in spaceflight, satellites, and space exploration on an unprecedented scale. A new powerful model for a large number of emerging superintelligence giants spreading across a landscape. ‚ÄúAny Sufficiently Advanced Technology is Indistinguishable from Magic.‚Äú ‚Äî Arthur C. Clarke Montr√©al.AI Space : Exploring the Stars and the UniverseWe are living in a period of unprecedented breakthroughs in science. Near future advances at the intersection of aerospace engineering and artificial intelligence hold out extraordinary prospects for the future of Mankind. ‚ÄúArtificial Intelligence is about recognising patterns, Artificial Life is about creating patterns.‚Äú ‚Äî Mizuki Oka et al, #alife2018 Montr√©al.AI Space believes in enhancing Humanity‚Äôs well-being by leveraging superintelligence to explore the Stars : The place where we truly belong. With higher ingenuity, we implements world‚Äêclass agents to design breakthrough deep learning algorithms with an understanding of our Universe. ‚ÄúI think transfer learning is the key to general intelligence. And I think the key to doing transfer learning will be the acquisition of conceptual knowledge that is abstracted away from perceptual details of where you learned it from.‚Äú ‚Äî Demis Hassabis Montr√©al.AI‚Äôs superhuman AI agents can learn from experience, simulate worlds and orchestrate meta-solutions. Montr√©al.AI Space is offering a new world age of impactful technical prowesses on a truly global scale. ‚ÄúOf course, particle physicists are among the first to realize that nature is compositional.‚Äú ‚Äî Yann LeCun References Why does deep and cheap learning work so well? ‚Äî Henry W. Lin, Max Tegmark, David Rolnick Introduction to astroML: Machine Learning for Astrophysics ‚Äî Jacob VanderPlas, Andrew J. Connolly, ZÀáeljko Ivezic ÃÅ, Alex Gray CosmoFlow: Using Deep Learning to Learn the Universe at Scale ‚Äî Mathuriya et al. Bayesian Deep Learning for Exoplanet Atmospheric Retrieval ‚Äî Frank Soboczenski, Michael D. Himes, Molly D. O‚ÄôBeirne, Simone Zorzan, Atilim Gunes Baydin, Adam D. Cobb, Daniel Angerhausen, Giada N. Arney, Shawn D. Domagal-Goldman Galaxy morphology prediction using capsule networks ‚Äî Katebi et al. Machine Learning for Physics and the Physics of Learning ‚Äî Steve Brunton, Cecilia Clementi, Yann LeCun, Marina Meila, Frank Noe, Francesco Paesani MINERVA-II1: Successful image capture, landing on Ryugu and hop! ‚Äî JAXA | Japan Aerospace Exploration Agency Restricted Boltzmann Machines for Collaborative Filtering ‚Äî Ruslan Salakhutdinov, Andriy Mnih, Geoffrey Hinton A Practical Guide to Training Restricted Boltzmann Machines ‚Äî Geoffrey Hinton GAIA DATA RELEASE 1 ‚Äî European Space Agency Evolved Virtual Creatures, Evolution Simulation, 1994 ‚Äî Karl Sims PHYSICS | MACHINE LEARNING - Recent papers combining the fields of physics and machine learning ‚Äî physicsml AI Model Could Help Robots Navigate on the Moon and Mars Without GPS ‚Äî NVIDIA Machine Learning and Likelihood-Free Inference in Particle Physics Slides | Video ‚Äî Kyle Cranmer Enabling Dark Energy Science with Deep Generative Models of Galaxy Images ‚Äî Siamak Ravanbakhsh, Francois Lanusse, Rachel Mandelbaum, Jeff Schneider, Barnabas Poczos Unity and DeepMind to Advance AI Research Using Virtual Worlds ‚Äî Business Wire A look at deep learning for science ‚Äî Prabhat Searching for Exotic Particles in High-Energy Physics with Deep Learning ‚Äî Pierre Baldi, Peter Sadowski, Daniel Whiteson Estimating Cosmological Parameters from the Dark Matter Distribution ‚Äî Siamak Ravanbakhsh, Junier Oliva, Sebastien Fromenteau, Layne C. Price, Shirley Ho, Jeff Schneider, Barnabas Poczos ‚ÄúGET ON A ROCKET SHIP‚Äù : Join Montr√©al.AI Space!Bringing contributions by scholars recognized as the foremost authorities in their fields, Montr√©al.AI Space is ahead of a trend that will profoundly influence the future of Humanity. Montr√©al.AI Space is looking for successful Associates &amp; Partners : Captains of Industries, Philanthropists, Iconic Tech Entrepreneurs, Financiers and World-Class Scholars to join us in this task of historic proportions. ‚úâÔ∏è Email Us : info@montreal.aiüìû Phone : +1.514.829.8269üåê Website : http://www.montreal.aiüìù LinkedIn : https://www.linkedin.com/in/montrealaiüèõ Headquarters : 350, PRINCE-ARTHUR STREET W., SUITE #2105, MONTREAL [QC], CANADA, H2X 3R4 *Executive Council and Administrative Head Office #AIFirst #MontrealAI #MontrealAISpace #MontrealArtificialIntelligence","link":"/MontrealAI.github.io/space/index.html"},{"title":"MONTR√âAL.AI | Montr√©al Artificial Intelligence","text":"MONTR√âAL.AI FINE ARTS (Pre-Release Early Version)Get Ready for the Launch!Creating Fine AI Arts History | Quintessential Launches in Major Cities! Quebec, Montreal, Vancouver, San Maarten, Beverly Hills, Caesar‚Äôs, Panama, Brasil, Paris, Milano, Principaut√© de Monaco, Geneva, Belgium, Germany, Luxembourg, Spain, Austria, London, Russian Federation, Aspen, Maui, SoHo, Israel, La Jolla, Macau, Dubai, India, Qatar, Saudi Arabia, Beijing, Shanghai, Hong Kong, Tokyo Midtown and Tapei. Pioneering Legendary Creations : Montr√©al.AI is Presenting a New World Age of Artistic Visions. A blending of Art and Science in the spirit of Leonardo da Vinci.Opening the doors to the AI art movement of the 21st Century, Montr√©al.AI Fine Arts is causing a huge stir amongst top art collectors and the most brilliant, influential, and iconoclastic figures worldwide. Captivating a discerning audience, Montr√©al.AI Fine Arts reflects the aesthetic diversity, conceptual richness and ‚Äòpurist‚Äô form of AI creativity expressed by the machine and is regarded as the highest in the hierarchy of genres. We are preparing a worldwide PR campaing with major talk show appearances and a TV documentary. Montreal.AI Academy Presents: AI 101 for Artists ‚ÄúThe Artists Creating with AI Won‚Äôt Follow Trends; THEY WILL SET THEM.‚Äú ‚Äî Montr√©al.AI Fine Arts A Well-Crafted 75 Minutes Tutorial for ArtistsEncompassing all facets of AI for Artists, the House of MONTREAL.AI Fine Arts introduces, with authority and insider knowledge: ‚ÄúArtificial Intelligence for Artists: The First World-Class Overview of AI for Artists‚Äú. Program: ‚ÄúUnveilling a World of Hidden Secrets‚Äù Group Reservation : secretariat@montreal.ai Designed for artists, #AI4Artists is created to inspire sentient beings who will shape the 21st Century. ‚ÄúTo identify truly path-breaking work, we would do better to stop asking where the boundary line lies between human artists‚Äô agency and that of AI toolsets, and instead start asking whether human artists are using AI to plumb greater conceptual and aesthetic depths than researchers or coders.‚Äú ‚Äî Tim Schneider and Naomi Rea, artnet, September 25, 2018 AI CONCERT : Defining the Genre of AI-Made MusicMONTREAL.AI Orchestra: Pioneering Superhuman Symphonies var exampleCallback = function() { console.log('Order complete!'); }; window.EBWidgets.createWidget({ // Required widgetType: 'checkout', eventId: '59763841258', iframeContainerId: 'eventbrite-widget-container-59763841258', // Optional iframeContainerHeight: 425, // Widget height in pixels. Defaults to a minimum of 425px if not provided onOrderComplete: exampleCallback // Method called when an order has successfully completed }); A New Day Has Come in Art IndustryFine AI Art-market history was made on October 25, 2018 when the first artificial intelligence artwork ever sold at Christie‚Äôs auction house shattered expectations, fetching $432,500. References The first AI artwork to be sold in a major auction achieves $432,500 after a bidding battle on the phones and via ChristiesLive ‚Äî Christie‚Äôs A sign of things to come? AI-produced artwork sells for $433K, smashing expectations ‚Äî Allyssia Alleyne, CNN Eerie AI-generated portrait fetches $432,500 at auction ‚Äî Devin Coldewey, TechCrunch ‚ÄúA spokesperson from Christie‚Äôs told us of the market‚Äôs excitement as this significant shift. ‚ÄúWe can confirm there were 5 different bidders from all parts of the world competing for this lot at that high price level, which seems a good indication of collector interest and future market potential for AI art generally‚Ä¶‚Äù‚Äú ‚Äî Adam Heardman, MutualArt The House of Montr√©al.AI Fine ArtsFine AI Arts History &amp; Heritage: The Building of a Legacy Montr√©al.AI Fine Arts is ahead of a trend that will profoundly impact the $350 billion / Year international fashion, fine arts &amp; jewelry industry ( üåê http://www.billionaire.tv/TheGazette.pdf ). A Renewal of the High Renaissance Ideals. | Montr√©al.AI Fine Arts artificial intelligence agents learn from experience to create superhuman artworks and artistic visions! Our creations are pure object of d√©sirs, fairytale lands and enchanted dreams conveying a feeling of exclusiveness : A fascinating, provocative and vibrant AI poetry. Harnessing the Deep Learning, Deep Reinforcement Learning, Generative Adversarial Nets, Meta-Learning and Self-Play on a truly global scale and deploying a passion offering insight with unusual breadth of elegance, refinement and style, The House of Montr√©al.AI Fine Arts pioneers unmistakable AI-generated superhuman creations and revolutionary designs, unveiling a majestic world of hidden secrets: ‚ùñ The Scent of AI (Perfumes)A line as enchanting as the muses it inspires. ‚ùñ Many-Worlds AI High Jewelry ( üíé )AI is poised to define the diamond industry of the 21st century. The House of Montreal.AI Fine Arts is pioneering AI Diamond cuts with an unprecedented culmination of brilliance, scintillation and dispersion for the Fashionees who will set the high jewelry trends of our era. ‚ùñ AI Artworks (Signed: Montreal.AI)Numbered and signed original prints including certificate of authenticity. An odyssey of cosmological, divine and mythological parallel universes of AI lullabies. A Legendary History: The Source of an Exceptional LegacyFrom: The General Secretariat of the Montr√©al.AI Fine Arts Executive Council A professional skilled catalyst versed in innovative research, high financial engineering and international luxury scene, Montreal.AI‚Äôs Founding Chairman Vincent Boucher received, on the 15th of October 2009, the prestigious Guinness World Records title for his Largest Cut Paraiba Tourmaline. A Work of Intellectual, Aesthetic and Technical Innovation | Vincent Boucher‚Äôs strategic foresight and ability to drive one of the most ambitious projects in History has pushed this highly experienced and seasoned human being to the forefront of its field, earning a well-deserved reputation on a truly global scale. ‚ÄúFinancier (Vincent Boucher) acquires world‚Äôs rarest stone.‚Äù‚Äú ‚Äî Mike King, The Gazette Exalting the purest and most beautiful creations, offering education and research revealing a unique range of critical, intellectual, and historical point of view, and opening the doors to a New Art Movement, The House of Montr√©al.AI Fine Arts fuels, with authority, the passion that drive today‚Äôs most successful AI artists. A Truly Special Celebration that is Certain to Make History!During the Renaissance, Pope Julius II commissioned painter Michelangelo for artwork of the Sistine Chapel ceiling at the Vatican. Today, you may commission AI artwork from The House of Montr√©al.AI Fine Arts. ‚ÄúThe defining art-making technology of our era will be AI.‚Äú ‚Äî Rama Allen For Andre Breton, the father of surrealism, the purpose of Art is the unification of the real and the imaginary. Montr√©al.AI Fine Arts makes Breton‚Äôs dream come true. A truly special celebration in the world of fine arts, fashion and high jewelry and one that is certain to make history! We are looking for Ambassadors &amp; Partners. ‚úâÔ∏è Email Us : info@montreal.aiüìû Phone : +1.514.829.8269üåê Website : http://www.montreal.aiüìù LinkedIn : https://www.linkedin.com/in/montrealaiüèõ Headquarters : 350, PRINCE-ARTHUR STREET W., SUITE #2105, MONTREAL [QC], CANADA, H2X 3R4 *Executive Council and Administrative Head Office #AIFirst #MontrealAI #MontrealAIArt #MontrealArtificialIntelligence","link":"/MontrealAI.github.io/art/index.html"},{"title":"MONTR√âAL.AI | Montr√©al Artificial Intelligence","text":"Montr√©al.AI AcademyARTIFICIAL INTELLIGENCE 101AI 101: The First World-Class Overview of AI for AllLocation: NRH Prince Arthur - Ballroom B, 3625 Avenue du Parc, Montreal (Qu√©bec), Canada, H2X 3P8. Tickets selling fast! THIS EVENT WILL SELL OUT.Encompassing all facets of AI, the General Secretariat of MONTREAL.AI presents, with authority and from insider knowledge: ‚ÄúArtificial Intelligence 101: The First World-Class Overview of AI for the General Public‚Äú. AI opens up a world of new possibilities. This AI 101 tutorial harnesses the fundamentals of artificial intelligence for the purpose of providing participants with powerful AI tools to learn, deploy and scale AI. ‚ÄúBreakthrough in machine learning would be worth 10 Microsofts.‚Äú ‚Äî Bill Gates A Well-Crafted Actionable 75 Minutes TutorialPOWERFUL &amp; USEFUL. This actionable tutorial is designed to entrust participants with the mindset, the skills and the tools to see artificial intelligence from an empowering new vantage point by : ‚Äî Exalting state of the art discoveries and science ;‚Äî Curating the best open-source codes &amp; implementations ; and‚Äî Embodying the impetus that drives today‚Äôs artificial intelligence. Program overview (‚ÄúPioneering an Impactful Understanding of AI‚Äù) ‚ùñ Opening Address Session 0 ¬∑ Getting Started In the Cloud On a Local Machine Session 1 ¬∑ Deep Learning Neural Networks Convolution Neural Networks (CNNs) Recurrent Neural Networks (RNNs) Unsupervised Deep Learning (Self-Supervised Learning, Generative Adversarial Nets and Variational Autoencoders) Session 2 ¬∑ Autonomous Agents Evolution Strategies Deep Reinforcement Learning Self Play: A Quantum Leap Deep Meta-Learning Session 3 ¬∑ Environments OpenAI Gym DeepMind Lab Unity ML-Agents ‚ùñ Special Address Tickets: https://montrealai101.eventbrite.ca var exampleCallback = function() { console.log('Order complete!'); }; window.EBWidgets.createWidget({ // Required widgetType: 'checkout', eventId: '54093711748', iframeContainerId: 'eventbrite-widget-container-54093711748', // Optional iframeContainerHeight: 425, // Widget height in pixels. Defaults to a minimum of 425px if not provided onOrderComplete: exampleCallback // Method called when an order has successfully completed }); Language: Tutorial given in English. Location: NRH Prince Arthur - Ballroom B, 3625 Avenue du Parc, Montreal (Qu√©bec), Canada, H2X 3P8. ‚ÄúThe best way to predict the future is to invent it.‚Äú ‚Äî Alan Kay VIP AI 101 CheatSheet for AllFor the purpose of entrusting all sentient beings with powerful AI tools to learn, deploy and scale AI in order to enhance their prosperity, to settle planetary-scale problems and to inspire those who, with AI, will shape the 21st Century, Montr√©al.AI introduces the ‚ÄúVIP AI 101 CheatSheet for All‚Äù. VIP AI 101 CheatSheet for Allhttp://www.montreal.ai/ai4all.pdf Artificial Intelligence 101 International WebinarLocation: This is an online event. Attendees will receive a link to join the event two (2) weeks prior to the event. Program overview (‚ÄúPioneering an Impactful Understanding of AI‚Äù) and tickets: https://ai101webinar.eventbrite.ca var exampleCallback = function() { console.log('Order complete!'); }; window.EBWidgets.createWidget({ // Required widgetType: 'checkout', eventId: '65144278290', iframeContainerId: 'eventbrite-widget-container-65144278290', // Optional iframeContainerHeight: 425, // Widget height in pixels. Defaults to a minimum of 425px if not provided onOrderComplete: exampleCallback // Method called when an order has successfully completed }); Language: Tutorial (webinar) given in English. Curated Open-Source Codes, Implementations and ScienceMontr√©al.AI is the largest artificial intelligence community in Canada. Join us and learn at https://www.facebook.com/groups/MontrealAI/ ! You are qualified for a career in machine learning! Andrew NgI want to pursue machine learning as a career but not sure if I am qualified... 0. Getting StartedAI opens up a world of new possibilities. Today‚Äôs artificial intelligence is powerful, useful and accessible to all. Tinker with Neural Networks : Neural Network Playground ‚Äî TensorFlow In the Cloud Free GPU compute via Colab. Colab: An easy way to learn and use TensorFlow ‚Äî TensorFlow Six easy ways to run your Jupyter Notebook in the cloud ‚Äî Data School Practice Immediately ‚Äî Goku Mohandas On a Local Machine Install Anaconda and Launch ‚ÄòAnaconda Navigator‚Äô. Update Jupyterlab and Launch the Application. Under Notebook, Click on ‚ÄòPython 3‚Äô. In the Browser TensorFlow.js: a library for developing and training ML models in JavaScript. TensorFlow dev summit Official TensorFlow.js Launch Introducing TensorFlow.js: Machine Learning in Javascript ‚Äî Josh Gordon, Sara Robinson TensorFlow.js: Machine Learning for the Web and Beyond ‚Äî Daniel Smilkov, Nikhil Thorat, Yannick Assogba, Ann Yuan, Nick Kreeger, Ping Yu, Kangyi Zhang, Shanqing Cai, Eric Nielsen, David Soergel, Stan Bileschi, Michael Terry, Charles Nicholson, Sandeep N. Gupta, Sarah Sirajuddin, D. Sculley, Rajat Monga, Greg Corrado, Fernanda B. Viegas, Martin Wattenberg Datasets Making it easier to discover datasets. Preliminary Readings ‚ÄúWhen you first study a field, it seems like you have to memorize a zillion things. You don‚Äôt. What you need is to identify the 3-5 core principles that govern the field. The million things you thought you had to memorize are various combinations of the core principles.‚Äú ‚Äî J. Reed Deep Learning ‚Äî Yann LeCun, Yoshua Bengio, Geoffrey Hinton Papers With Code! | Over 950+ ML tasks, 500+ evaluation tables (including state of the art results) and 8500+ papers with code! ‚Äî Atlas ML Learn X in Y minutes (Where X=python3) ‚Äî Louie Dinh 6.S191: Introduction to Deep Learning | MIT‚Äôs official introductory course on deep learning methods and applications. ‚Äî Alexander Amini and Ava Soleimany Practical Deep Learning for Coders 2019 ‚Äî Jeremy Howard Foundations Built for a General Theory of Neural Networks ‚Äî Kevin Hartnett The Matrix Calculus You Need For Deep Learning ‚Äî Terence Parr, Jeremy Howard Introduction to the math of backprop ‚Äî Deb Panigrahi Introduction to Applied Linear Algebra ‚Äì Vectors, Matrices, and Least Squares ‚Äî Stephen Boyd and Lieven Vandenberghe, Cambridge University Press What are the limits of deep learning? ‚Äî M. Mitchell Waldrop ‚ÄúA birds-eye view of optimization algorithms‚Äù ‚Äî Fabian Pedregosa Using Nucleus and TensorFlow for DNA Sequencing Error Correction ‚Äî Gunjan Baid, Helen Li and Pi-Chuan Chang Dive into Deep Learning ‚Äî Aston Zhang, Zack C. Lipton, Mu Li, Alex J. Smola How to visualize decision trees ‚Äî Terence Parr, Prince Grover Machine Learning for Visualization ‚Äî Ian Johnson Seeing Theory: A visual introduction to probability and statistics. ‚Äî Daniel Kunin et al. explained.ai | Deep explanations of machine learning ‚Äî Terence Parr What is torch.nn really? ‚Äî Jeremy Howard Scipy Lecture Notes ‚Äî Scipy Deep Learning and Robotics ‚Äî Pieter Abbeel Natasha Jaques: ‚ÄúRecent advances in AI and machine learning‚Äù | Starsconf 2018 ‚Äî Natasha Jaques | Starsconf 2018 CS 188 | Introduction to Artificial Intelligence ‚Äî Pieter Abbeel, Dan Klein A Concise Handbook of TensorFlow ‚Äî Xihan Li The WIRED Guide to artificial intelligence ‚Äî WIRED How to teach yourself hard things ‚Äî Julia Evans UFLDL (Unsupervised Feature Learning and Deep Learning) Tutorial ‚Äî Andrew Ng, Jiquan Ngiam, Chuan Yu Foo, Yifan Mai, Caroline Suen Interview with The Youngest Kaggle Grandmaster: Mikel Bober-Irizar (anokas) ‚Äî Sanyam Bhutani, Hacker Noon Cutting-Edge Face Recognition is Complicated. These Spreadsheets Make it Easier. ‚Äî Dave Smith A radical new neural network design could overcome big challenges in AI ‚Äî Karen Hao Remarkable problem-solving ability of unicellular amoeboid organism and its mechanism ‚Äî Liping Zhu, Song-Ju Kim, Masahiko Hara, Masashi Aono Competitive Programmer‚Äôs Handbook ‚Äî Antti Laaksonen Machine Learning from scratch! ‚Äî Quan Tran Rules of Machine Learning: Best Practices for ML Engineering ‚Äî Martin Zinkevich A Neural Network in 11 lines of Python ‚Äî iamtrask ‚Äú1. Multiply things together 2. Add them up 3. Replaces negatives with zeros 4. Return to step 1, a hundred times.‚Äú ‚Äî Jeremy Howard How to build your own Neural Network from scratch in Python ‚Äî James Loy Deep Gaussian Processes ‚Äî Neil D. Lawrence Magic Sketchpad ‚Äî Monica Dinculescu AI Transformation Playbook ‚Äî Andrew Ng Understand TensorFlow by mimicking its API from scratch ‚Äî Dominic Elm Bias-Variance Decomposition ‚Äî Sebastian Raschka SpaceSheet: Interactive Latent Space Exploration through a Spreadsheet Interface Paper | Demo | Tool ‚Äî Bryan Loh, Tom White On intelligence: its creation and understanding ‚Äî Surya Ganguli NeurIPS 2018 Videos ‚Äî Thirty-second Conference on Neural Information Processing Systems Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks ‚Äî Adam Geitgey The Neural Aesthetic ‚Äî Gene Kogan MONet: Unsupervised Scene Decomposition and Representation ‚Äî Christopher P. Burgess, Loic Matthey, Nicholas Watters, Rishabh Kabra, Irina Higgins, Matt Botvinick, Alexander Lerchner Popular Machine Learning Algorithms Explained Project Jupyter | GitHub ‚Äî Oleksii Trekhleb Introduction to Artificial Intelligence, ULi√®ge, Fall 2018. ‚Äî Gilles Louppe Deep Learning cheatsheets for Stanford‚Äôs CS 230 ‚Äî Afshine Amidi, Shervine Amidi TensorFlow Blog ‚Äî TensorFlow Machine Learning From Scratch ‚Äî Erik Linder-Nor√©n A Beginner‚Äôs Guide to the Mathematics of Neural Networks ‚Äî A.C.C. Coolen An embedding is a mapping from discrete objects, such as words, to vectors of real numbers. 1. Deep LearningDeep learning allows computational models that are composed of multiple processing layers to learn REPRESENTATIONS of (raw) data with multiple levels of abstraction. At a high-level, neural networks are either encoders, decoders, or a combination of both. ‚ÄúDL is essentially a new style of programming‚Äì‚Äùdifferentiable programming‚Äù‚Äìand the field is trying to work out the reusable constructs in this style. We have some: convolution, pooling, LSTM, GAN, VAE, memory units, routing units, etc.‚Äú ‚Äî Thomas G. Dietterich 1.1 Neural Networks ‚ÄúNeural networks‚Äù are a sad misnomer. They‚Äôre neither neural nor even networks. They‚Äôre chains of differentiable, parameterized geometric functions, trained with gradient descent (with gradients obtained via the chain rule). A small set of highschool-level ideas put together.‚Äú ‚Äî Fran√ßois Chollet AI Playbook ‚Äî Andreessen Horowitz Clear Explanations of Machine Learning ‚Äî Distill Deep Learning Book ‚Äî Ian Goodfellow, Yoshua Bengio, Aaron Courville Neural Networks and Deep Learning ‚Äî Michael Nielsen Deep Learning ‚Äî Vincent Vanhoucke | Google A Complete Implementation of a Toy Neural Network ‚Äî Stanford CS class CS231n Neural networks: training with backpropagation ‚Äî Jeremy Jordan Introduction to Machine Learning for Coders ‚Äî Jeremy Howard Machine Learning Yearning ‚Äî Andrew Ng Effective TensorFlow for Non-Experts ‚Äî Google Developers Neural Network as Ordinary Differential Equations ‚Äî Kevin Gibson A curated collection of inspirational AI-powered JavaScript apps ‚Äî Elle Haproff, Asim Hussain, Osama Jandali Pytorch Implementation of Neural Processes ‚Äî Chris Ormandy A Few Unusual Autoencoders ‚Äî Colin Raffel Science of AI | How AI Training Scales ‚Äî OpenAI Pytorch implementation of JointVAE, a framework for disentangling continuous and discrete factors of variation ‚Äî Schlumberger Software Technology A New TensorFlow Hub Web Experience ‚Äî Andr√© Susano Pinto, Clemens Mewald Approximate Fisher Information Matrix to Characterise the Training of Deep Neural Networks ‚Äî Zhibin Liao, Tom Drummond, Ian Reid, Gustavo Carneiro Deep Learning on Graphs: A Survey ‚Äî Ziwei Zhang, Peng Cui, Wenwu Zhu TF Jam ‚Äî Shooting Hoops with Machine Learning ‚Äî Abe Haskins Building Web App for Computer Vision Model &amp; Deploying to Production in 10 Minutes*: A Detailed Guide ‚Äî Pankaj Mathur Measuring the Effects of Data Parallelism on Neural Network Training ‚Äî Christopher J. Shallue, Jaehoon Lee, Joe Antognini, Jascha Sohl-Dickstein, Roy Frostig, George E. Dahl Photo Wake-Up: 3D Character Animation from a Single Photo Paper | Project Page ‚Äî Chung-Yi Weng, Brian Curless, Ira Kemelmacher-Shlizerman Relational inductive biases, deep learning, and graph networks ‚Äî Peter W. Battaglia, Jessica B. Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi, Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, Caglar Gulcehre, Francis Song, Andrew Ballard, Justin Gilmer, George Dahl, Ashish Vaswani, Kelsey Allen, Charles Nash, Victoria Langston, Chris Dyer, Nicolas Heess, Daan Wierstra, Pushmeet Kohli, Matt Botvinick, Oriol Vinyals, Yujia Li, Razvan Pascanu Avito Demand Prediction Challenge : Kaggle winner explains how to combine categorical, numerical, image and text features into a single NN that gets you into top 10 without stacking ‚Äî Little Boat fast.ai | Making neural nets uncool again Intro Machine Learning | Practical Deep Learning | Cutting Edge Deep Learning | Computational Linear Algebra ‚Äî Jeremy Howard, Rachel Thomas | Fast.AI 1.1.1 Universal Approximation TheoremThe universal approximation theorem states that a feed-forward network with a single hidden layer containing a finite number of neurons can solve any given problem to arbitrarily close accuracy as long as you add enough parameters. Neural Networks + Gradient Descent + GPU: Infinitely flexible function: Neural Networks (multiple hidden layers: Deep Learning) ; All-purpose parameter fitting: Backpropagation ; and Fast and scalable: GPU. When a choice must be made, just feed the (raw) data to a deep neural network (universal function approximator). 1.2 Convolution Neural NetworkIn images, local combinations of edges form motifs, motifs assemble into parts, and parts form objects. The deep convolutional network, inspired by Hubel and Wiesel‚Äôs seminal work on early visual cortex, uses hierarchical layers of tiled convolutional filters to mimic the effects of receptive fields, thereby exploiting the local spatial correlations present in images. A ConvNet is made up of Layers. Every Layer has a simple API: It transforms an input 3D volume to an output 3D volume with some differentiable function that may or may not have parameters. ‚ÄúI admire the elegance of your method of computation; it must be nice to ride through these fields upon the horse of true mathematics while the like of us have to make our way laboriously on foot.‚Äú ‚Äî A. Einstein CNN Is All You Need ‚Äî Qiming Chen, Ren Wu Feature Visualization ‚Äî Chris Olah, Alexander Mordvintsev, Ludwig Schubert Explanatory Graphs for CNNs ‚Äî Quanshi Zhang, Xin Wang, Ruiming Cao, Ying Nian Wu, Feng Shi, Song-Chun Zhu Understanding Neural Networks Through Deep Visualization ‚Äî Jason Yosinski, Jeff Clune, Anh Nguyen, Thomas Fuchs, and Hod Lipson MedicalTorch ‚Äî Christian S. Perone How to visualize convolutional features in 40 lines of code ‚Äî Fabio M. Graetz Deep Learning for Generic Object Detection: A Survey ‚Äî Li Liu, Wanli Ouyang, Xiaogang Wang, Paul Fieguth, Jie Chen, Xinwang Liu, Matti Pietik√§inen A Unified Theory of Early Visual Representations from Retina to Cortex through Anatomically Constrained Deep CNNs ‚Äî Jack Lindsey, Samuel A. Ocko, Surya Ganguli, Stephane Deny The Building Blocks of Interpretability ‚Äî Chris Olah, Arvind Satyanarayan, Ian Johnson, Shan Carter, Ludwig Schubert, Katherine Ye, Alexander Mordvintsev Detectron : State-of-the-art Object Detection ‚Äî Ross Girshick and Ilija Radosavovic and Georgia Gkioxari and Piotr Doll\\‚Äô{a}r and Kaiming He YOLOv3: An Incremental Improvement | WebSite | YouTube ‚Äî Joseph Redmon, Ali Farhadi From Recognition to Cognition: Visual Commonsense Reasoning ‚Äî Rowan Zellers, Yonatan Bisk, Ali Farhadi, Yejin Choi AdVis.js : Exploring Fast Gradient Sign Method ‚Äî Jason Lin, Dilara Soylu Machine Learning for Artists | Demos Page | This is how convolution works ‚Äî Machine Learning for Artists Deep Painterly Harmonization | Notebook ‚Äî Sylvain Gugger A Deep Learning based magnifying glass ‚Äî Francesco Cardinale How Convolutional Neural Networks Work ‚Äî Brandon Rohrer TensorSpace: Neural network 3D visualization framework ‚ÄîTensorSpace 1.3 Recurrent Neural NetworksFor sequential inputs. Recurrent neural networks are networks with loops in them, allowing information to persist. RNNs process an input sequence one element at a time, maintaining in their hidden units a ‚Äòstate vector‚Äô that implicitly contains information about the history of all the past elements of the sequence. Long Short-Term Memory ‚Äî Sepp Hochreiter, J√ºrgen Schmidhuber Understanding LSTM Networks ‚Äî Christopher Olah Can Neural Networks Remember? ‚Äî Vishal Gupta Attention and Augmented RNN ‚Äî Olah &amp; Carter, 2016 Computer, respond to this email ‚Äî Post by Greg Corrado How do Mixture Density RNNs Predict the Future? ‚Äî Kai Olav Ellefsen, Charles Patrick Martin, Jim Torresen Reversible Recurrent Neural Networks ‚Äî Matthew MacKay, Paul Vicol, Jimmy Ba, Roger Grosse Recurrent Relational Networks Blog | arXiv | Code ‚Äî Rasmus Berg Palm, Ulrich Paquet, Ole Winther The Unreasonable Effectiveness of Recurrent Neural Networks ‚Äî Andrej Karpathy Massive Exploration of Neural Machine Translation Architectures arXiv | Docs | Code ‚Äî Denny Britz, Anna Goldie, Minh-Thang Luong, Quoc Le A TensorFlow implementation of : ‚ÄúHybrid computing using a neural network with dynamic external memory‚Äù GitHub ‚Äî Alex Graves, Greg Wayne, Malcolm Reynolds, Tim Harley, Ivo Danihelka, Agnieszka Grabska-Barwi≈Ñska, Sergio G√≥mez Colmenarejo, Edward Grefenstette, Tiago Ramalho, John Agapiou, Adri√† Puigdom√®nech Badia, Karl Moritz Hermann, Yori Zwols, Georg Ostrovski, Adam Cain, Helen King, Christopher Summerfield, Phil Blunsom, Koray Kavukcuoglu &amp; Demis Hassabis ‚ÄúI feel like a significant percentage of Deep Learning breakthroughs ask the question ‚Äúhow can I reuse weights in multiple places?‚Äù‚Äì Recurrent (LSTM) layers reuse for multiple timesteps‚Äì Convolutional layers reuse in multiple locations.‚Äì Capsules reuse across orientation.‚Äú ‚Äî Trask 1.4 Capsules Dynamic Routing Between Capsules ‚Äî Sara Sabour, Nicholas Frosst, Geoffrey E Hinton Capsule Networks (CapsNets) ‚Äì Tutorial ‚Äî Aur√©lien G√©ron Understanding Hinton‚Äôs Capsule Networks. Part I: Intuition. ‚Äî Max Pechyonkin Capsules for Object Segmentation ‚Äî Rodney LaLonde, Ulas Bagci Brain Tumor Type Classification via Capsule Networks ‚Äî Parnian Afshar, Arash Mohammadi, Konstantinos N. Plataniotis A Tensorflow implementation of CapsNet ‚Äî Huadong Liao 1.5 Unsupervised LearningTrue intelligence will require independent learning strategies. Unsupervised learning is a paradigm for creating AI that learns without a particular task in mind: learning for the sake of learning. It captures some characteristics of the joint distribution of the observed random variables (learn the underlying structure). Self-supervised learning is derived form unsupervised learning where the data provides the supervision. 1.5.1 Generative Adversarial NetworkSimultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. $$\\min_{\\theta_g} \\max_{\\theta_d} [{\\rm IE_{x\\sim p_{data}(x)}} [log D_{\\theta_d}(x)] + {\\rm IE_{z\\sim p_z(z)}} [log(1 - D_{\\theta_d}(G_{\\theta_g}(z)))]]$$ ‚ÄúWhat I cannot create, I do not understand.‚Äú ‚Äî Richard Feynman This framework corresponds to a minimax two-player game. Generative Adversarial Nets ‚Äî Goodfellow et al. Generative Models ‚Äî OpenAI GAN Lab: Play with Generative Adversarial Networks (GANs) in your browser! ‚Äî Minsuk Kahng, Nikhil Thorat, Polo Chau, Fernanda Vi√©gas, Martin Wattenberg Generative Adversarial Networks (GANs) in 50 lines of code (PyTorch) ‚Äî Dev Nag TensorFlow-GAN (TFGAN) ‚Äî TensorFlow Few-Shot Adversarial Learning of Realistic Neural Talking Head Models Wasserstein GAN GANSynth: Generate high-fidelity audio with GANs! SC-FEGAN: Face Editing Generative Adversarial Network CariGANs: Unpaired Photo-to-Caricature Translation GANpaint Paint with GAN units PyTorch pretrained BigGAN Neural scene representation and rendering ‚Äî S. M. Ali Eslami, Danilo J. Rezende, Frederic Besse, Fabio Viola, Ari S. Morcos, Marta Garnelo, Avraham Ruderman, Andrei A. Rusu, Ivo Danihelka, Karol Gregor, David P. Reichert, Lars Buesing, Theophane Weber, Oriol Vinyals, Dan Rosenbaum, Neil Rabinowitz, Helen King, Chloe Hillier, Matt Botvinick, Daan Wierstra, Koray Kavukcuoglu, Demis Hassabis Recycle-GAN: Unsupervised Video Retargeting Paper | Blog ‚Äî Aayush Bansal, Shugao Ma, Deva Ramanan, Yaser Sheikh On Self Modulation for Generative Adversarial Networks ‚Äî Ting Chen, Mario Lucic, Neil Houlsby, Sylvain Gelly Bayesian GAN arXiv | GitHub ‚Äî Yunus Saatchi, Andrew Gordon Wilson Adversarial Transfer Learning ‚Äî Garrett Wilson, Diane J. Cook Generating Memoji from Photos ‚Äî Pat Niemeyer GANPaint ‚Äî MIT-IBM Watson AI Lab The GAN Zoo ‚Äî Avinash Hindupur A collection of GANs TensorFlow | PyTorch StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks Paper | Code StyleGAN for art This Person Does Not Exist Which Person Is Real? This Resume Does Not Exist This Waifu Does Not Exist Encoder for Official TensorFlow Implementation How to recognize fake AI-generated images ‚Äî Kyle McDonald Demo of BigGAN in an official Colaboratory notebook (backed by a GPU) 1.5.2 Variational Auto-Encoders (VAEs)Variational Auto-Encoders (VAEs) are powerful models for learning low-dimensional representations. Debiasing Facial Detection Systems - Colab SpaceSheet: Interactive Latent Space Exploration with a Spreadsheet MusicVAE: Learning latent spaces for musical scores Slides: A Few Unusual Autoencoders Generative models in Tensorflow 2 Disentangled VAE‚Äôs (DeepMind 2016) ‚ÄúI think transfer learning is the key to general intelligence. And I think the key to doing transfer learning will be the acquisition of conceptual knowledge that is abstracted away from perceptual details of where you learned it from.‚Äú ‚Äî Demis Hassabis 2. Autonomous AgentsReinforcement learning (RL) studies how an agent can learn how to achieve goals in a complex, uncertain environment. An autonomous agent is any device that perceives its environment and takes actions that maximize its chance of success at some goal. At the bleeding edge of AI, autonomous agents can learn from experience, simulate worlds and orchestrate meta-solutions. Here‚Äôs an informal definition of the universal intelligence of agent `\\pi` $$\\Upsilon(\\pi) := \\sum\\limits_{\\mu \\in E} 2^{-K(\\mu)} V^{\\pi}_{\\mu}$$ ‚ÄúIntelligence measures an agent‚Äôs ability to achieve goals in a wide range of environments.‚Äú ‚Äî Shane Legg 2.1 Evolution Strategies ‚ÄúEvolution is a slow learning algorithm that with the sufficient amount of compute produces a human brain.‚Äú ‚Äî Wojciech Zaremba Evolution and neural networks proved a potent combination in nature. Natural evolutionary strategy directly evolves the weights of a DNN and performs competitively with the best deep reinforcement learning algorithms. Neuroevolution enables capabilities that are typically unavailable to gradient-based approaches. A Visual Guide to Evolution Strategies ‚Äî David Ha Evolution Strategies as a Scalable Alternative to Reinforcement Learning ‚Äî OpenAI The Surprising Creativity of Digital Evolution: A Collection of Anecdotes from the Evolutionary Computation and Artificial Life Research Communities ‚Äî Joel Lehman, Jeff Clune, Dusan Misevic, Christoph Adami, Lee Altenberg, Julie Beaulieu, Peter J. Bentley, Samuel Bernard, Guillaume Beslon, David M. Bryson, Patryk Chrabaszcz, Nick Cheney, Antoine Cully, Stephane Doncieux, Fred C. Dyer, Kai Olav Ellefsen, Robert Feldt, Stephan Fischer, Stephanie Forrest, Antoine Fr√©noy, Christian Gagn√©, Leni Le Goff, Laura M. Grabowski, Babak Hodjat, Frank Hutter, Laurent Keller, Carole Knibbe, Peter Krcah, Richard E. Lenski, Hod Lipson, Robert MacCurdy, Carlos Maestre, Risto Miikkulainen, Sara Mitri, David E. Moriarty, Jean-Baptiste Mouret, Anh Nguyen, Charles Ofria, Marc Parizeau, David Parsons, Robert T. Pennock, William F. Punch, Thomas S. Ray, Marc Schoenauer, Eric Shulte, Karl Sims, Kenneth O. Stanley, Fran√ßois Taddei, Danesh Tarapore, et al. (4 additional authors not shown) Evolving Neural Networks ‚Äî Risto Miikkulainen Recombination of Artificial Neural Networks ‚Äî Aaron Vose, Jacob Balma, Alex Heye, Alessandro Rigazzi, Charles Siegel, Diana Moise, Benjamin Robbins, Rangan Sukumar Nevergrad: An open source tool for derivative-free optimization ‚Äî J. Rapin and O. Teytaud Evolved Policy Gradients ‚Äî Rein Houthooft, Richard Y. Chen, Phillip Isola, Bradly C. Stadie, Filip Wolski, Jonathan Ho, Pieter Abbeel Using Evolutionary AutoML to Discover Neural Network Architectures ‚Äî Google AI Neural architecture search has advanced to the point where it can outperform human-designed models. ‚Äú‚Ä¶ evolution ‚Äî whether biological or computational ‚Äî is inherently creative, and should routinely be expected to surprise, delight, and even outwit us.‚Äú ‚Äî The Surprising Creativity of Digital Evolution, Lehman et al. 2.2 Deep Reinforcement LearningIn reinforcement learning, an agent interacts with an environment through a Markov decision process. The goal in reinforcement learning is to train the agent to maximize the sum of future rewards, called the return. Reinforcement Learning: An Introduction ‚Äî Andrew Barto and Richard S. Sutton Spinning Up as a Deep RL Researcher ‚Äî Joshua Achiam Intuitive RL: Intro to Advantage-Actor-Critic (A2C) ‚Äî Rudy Gilman Simple Beginner‚Äôs guide to Reinforcement Learning &amp; its implementation ‚Äî Faizan Shaikh Spinning Up in Deep RL ‚Äî Joshua Achiam AlphaStar: Mastering the Real-Time Strategy Game StarCraft II ‚Äî Oriol Vinyals, Igor Babuschkin, Junyoung Chung, Michael Mathieu, Max Jaderberg, Wojtek Czarnecki, Andrew Dudzik, Aja Huang, Petko Georgiev, Richard Powell, Timo Ewalds, Dan Horgan, Manuel Kroiss, Ivo Danihelka, John Agapiou, Junhyuk Oh, Valentin Dalibard, David Choi, Laurent Sifre, Yury Sulsky, Sasha Vezhnevets, James Molloy, Trevor Cai, David Budden, Tom Paine, Caglar Gulcehre, Ziyu Wang, Tobias Pfaff, Toby Pohlen, Dani Yogatama, Julia Cohen, Katrina McKinney, Oliver Smith, Tom Schaul, Timothy Lillicrap, Chris Apps, Koray Kavukcuoglu, Demis Hassabis, David Silver Creating a Zoo of Atari-Playing Agents to Catalyze the Understanding of Deep Reinforcement Learning ‚Äî Felipe Petroski Such, Vashisht Madhavan, Rosanne Liu, Rui Wang, Yulun Li, Jeff Clune, Joel Lehman An Introduction to Deep Reinforcement Learning ‚Äî Vincent Francois-Lavet, Peter Henderson, Riashat Islam, Marc G. Bellemare, Joelle Pineau Welcome to Spinning Up in Deep RL! ‚Äî OpenAI A (Long) Peek into Reinforcement Learning ‚Äî Lilian Weng A Theoretical Analysis of Deep Q-Learning ‚Äî Zhuora Yang, Yuchen Xie, Zhaoran Wang Monte Carlo Tree Search ‚Äì beginners guide ‚Äî Kamil Czarnog√≥rski Quantifying Generalization in Reinforcement Learning ‚Äî OpenAI Relational Deep Reinforcement Learning ‚Äî Vinicius Zambaldi, David Raposo, Adam Santoro, Victor Bapst, Yujia Li, Igor Babuschkin, Karl Tuyls, David Reichert, Timothy Lillicrap, Edward Lockhart, Murray Shanahan, Victoria Langston, Razvan Pascanu, Matthew Botvinick, Oriol Vinyals, Peter Battaglia Getting Started With MarathonEnvs v0.5.0a ‚Äî Joe Booth AlphaZero: Shedding new light on the grand games of chess, shogi and Go ‚Äî David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, Timothy Lillicrap, Karen Simonyan, Demis Hassabis DQN Adventure: from Zero to State of the Art ‚Äî higgsfield SURREAL: Open-Source Reinforcement Learning Framework and Robot Manipulation Benchmark ‚Äî Linxi Fan, Yuke Zhu, Jiren Zhu, Zihua Liu, Anchit Gupta, Joan Creus-Costa, Silvio Savarese, Li Fei-Fei Learning to Act by Predicting the Future ‚Äî Alexey Dosovitskiy, Vladlen Koltun AlphaFold: Using AI for scientific discovery ‚Äî Andrew Senior, John Jumper, Demis Hassabis POET: Endlessly Generating Increasingly Complex and Diverse Learning Environments and their Solutions through the Paired Open-Ended Trailblazer ‚Äî Rui Wang, Joel Lehman, Jeff Clune, Kenneth O. Stanley Reinforcement Learning with Prediction-Based Rewards ‚Äî Yura Burda, Harri Edwards, OpenAI Playing hard exploration games by watching YouTube Paper | YouTube ‚Äî Yusuf Aytar, Tobias Pfaff, David Budden, Tom Le Paine, Ziyu Wang, Nando de Freitas Exploration by Random Network Distillation Paper | Code ‚Äî Yuri Burda, Harrison Edwards, Amos Storkey, Oleg Klimov Large-Scale Study of Curiosity-Driven Learning Paper | Code ‚Äî Yuri Burda, Harri Edwards, Deepak Pathak, Amos Storkey, Trevor Darrell, Alexei A. Efros OpenAI Baselines : A2C | ACER | ACKTR | DDPG | DQN | GAIL | HER | PPO2 | TRPO ‚Äî OpenAI Stable Baselines is a set of improved implementations of Reinforcement Learning (RL) algorithms based on OpenAI Baselines Docs | Blog | Code ‚Äî Antonin Raffin TRPO-GAE Blog | arXiv | arXiv ‚Äî OpenAI Improvised Robotic Design with Found Objects ‚Äî Azumi Maekawa, Ayaka Kume, Hironori Yoshida, Jun Hatori, Jason Naradowsky, Shunta Saito A3C arXiv | Medium | Code ‚Äî OpenAI Deep Reinforcement Learning ‚Äî Sergey Levine Vel: PyTorch meets baselines ‚Äî Jerry Continual Match Based Training in Pommerman: Technical Report ‚Äî Peng Peng, Liang Pang, Yufeng Yuan, Chao Gao Actor-Critic Policy Optimization in Partially Observable Multiagent Environments ‚Äî Sriram Srinivasan, Marc Lanctot, Vinicius Zambaldi, Julien Perolat, Karl Tuyls, Remi Munos, Michael Bowling TensorFlow Reinforcement Learning ‚Äî DeepMind TensorFlow Agents ‚Äî TensorFlow TensorFlow.js Implementation of DeepMind‚Äôs AlphaZero Algorithm for Chess Live Demo | Code ‚Äî Fran√ßois Pays DiCE: The Infinitely Differentiable Monte Carlo Estimator ‚Äî Vitaly Kurin, Jakob Foerster, Shimon Whiteson TorchCraftAI: A bot platform for machine learning research on StarCraft¬Æ: Brood War¬Æ ‚Äî Facebook Curiosity and Procrastination in Reinforcement Learning ‚Äî Nikolay Savinov, Timothy Lillicrap Hierarchical Actor-Critic ‚Äî Andrew Levy, Robert Platt, Kate Saenko Montezuma‚Äôs Revenge Solved by Go-Explore, a New Algorithm for Hard-Exploration Problems ‚Äî Adrien Ecoffet, Joost Huizinga, Joel Lehman, Kenneth O. Stanley, Jeff Clune Computational Theories of Curiosity-Driven Learning ‚Äî Pierre-Yves Oudeyer Depth-Limited Solving for Imperfect-Information Games ‚Äî Noam Brown, Tuomas Sandholm, Brandon Amos Optimizing Expectations: From Deep Reinforcement Learning to Stochastic Computation Graphs ‚Äî John Schulman Neural Episodic Control ‚Äî Alexander Pritzel, Benigno Uria, Sriram Srinivasan, Adri√† Puigdom√®nech, Oriol Vinyals, Demis Hassabis, Daan Wierstra, Charles Blundell RLlib: Abstractions for Distributed Reinforcement Learning ‚Äî Eric Liang, Richard Liaw, Philipp Moritz, Robert Nishihara, Roy Fox, Ken Goldberg, Joseph E. Gonzalez, Michael I. Jordan, Ion Stoica TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep Reinforcement Learning ‚Äî Gregory Farquhar, Tim Rockt√§schel, Maximilian Igl, Shimon Whiteson Q-map: a Convolutional Approach for Goal-Oriented Reinforcement Learning ‚Äî Fabio Pardo, Vitaly Levdik, Petar Kormushev Learning to Search with MCTSnets ‚Äî Arthur Guez, Th√©ophane Weber, Ioannis Antonoglou, Karen Simonyan, Oriol Vinyals, Daan Wierstra, R√©mi Munos, David Silver Convergence of Value Aggregation for Imitation Learning ‚Äî Ching-An Cheng, Byron Boots Dopamine : DQN | C51 | Rainbow | Implicit Quantile Network ‚Äî Marc G. Bellemare, Pablo Samuel Castro, Carles Gelada, Saurabh Kumar, Subhodeep Moitra S-RL Toolbox: Reinforcement Learning (RL) and State Representation Learning (SRL) for Robotics ‚Äî Antonin RAFFIN Advanced Deep Learning and Reinforcement Learning ‚Äî DeepMind Researchers Reinforcement Learning for Improving Agent Design arXiv | Blog ‚Äî David Ha Deep Reinforcement Learning from Human Preferences arXiv | Blog | Code ‚Äî OpenAI Introduction to Learning to Trade with Reinforcement Learning ‚Äî Denny Britz Closing the Sim-to-Real Loop: Adapting Simulation Randomization with Real World Experience ‚Äî Yevgen Chebotar, Ankur Handa, Viktor Makoviychuk, Miles Macklin, Jan Issac, Nathan Ratliff, Dieter Fox Robustness via Retrying: Closed-Loop Robotic Manipulation with Self-Supervised Learning ‚Äî Frederik Ebert, Sudeep Dasari, Alex X. Lee, Sergey Levine, Chelsea Finn CURIOUS: Intrinsically Motivated Multi-Task, Multi-Goal Reinforcement Learning ‚Äî C√©dric Colas, Olivier Sigaud, Pierre-Yves Oudeyer Bayesian Optimization in AlphaGo ‚Äî Yutian Chen, Aja Huang, Ziyu Wang, Ioannis Antonoglou, Julian Schrittwieser, David Silver, Nando de Freitas One-Shot High-Fidelity Imitation: Training Large-Scale Deep Nets with RL ‚Äî Tom Le Paine, Sergio G√≥mez Colmenarejo, Ziyu Wang, Scott Reed, Yusuf Aytar, Tobias Pfaff, Matt W. Hoffman, Gabriel Barth-Maron, Serkan Cabi, David Budden, Nando de Freitas Optimizing Agent Behavior over Long Time Scales by Transporting Value ‚Äî Chia-Chun Hung, Timothy Lillicrap, Josh Abramson, Yan Wu, Mehdi Mirza, Federico Carnevale, Arun Ahuja, Greg Wayne Large-Scale Study of Curiosity-Driven Learning ‚Äî Yuri Burda, Harri Edwards, Deepak Pathak, Amos Storkey, Trevor Darrell, Alexei A. Efros Learning to Dress: Synthesizing Human Dressing Motion via Deep Reinforcement Learning ‚Äî Alexander Clegg, Wenhao Yu, Jie Tan, C. Karen Liu, Greg Turk, SIGGRAPH Asia 2018 Automatic Poetry Generation with Mutual Reinforcement Learning ‚Äî Xiaoyuan Yi, Maosong Sun, Ruoyu Li, Wenhao Li Learning to Communicate with Deep Multi-Agent Reinforcement Learning in PyTorch ‚Äî Minqi Jiang Learning to Navigate the Web ‚Äî Anonymous Understanding &amp; Generalizing AlphaGo Zero ‚Äî Anonymous Deep RL Bootcamp ‚Äî Pieter Abbeel, Yan (Rocky) Duan, Xi (Peter) Chen, Andrej Karpathy 2.2.1 Model-Based RLIn Model-Based RL, the agent generates predictions about the next state and reward before choosing each action. World Models ‚Äî David Ha, J√ºrgen Schmidhuber Imagination-Augmented Agents for Deep Reinforcement Learning ‚Äî Th√©ophane Weber, S√©bastien Racani√®re, David P. Reichert, Lars Buesing, Arthur Guez, Danilo Jimenez Rezende, Adria Puigdom√®nech Badia, Oriol Vinyals, Nicolas Heess, Yujia Li, Razvan Pascanu, Peter Battaglia, Demis Hassabis, David Silver, Daan Wierstra Learning Latent Dynamics for Planning from Pixels ‚Äî Hafner et al. Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm (AlphaZero) ‚Äî Silver et al. ‚ÄúNo superintelligent AI is going to bother with a task that is harder than hacking its reward function.‚Äú ‚Äî The Lebowski theorem 2.3 Self PlaySelf-play mirrors similar insights from coevolution. AlphaGo Zero showed that algorithms matter much more than big data and massive amounts of computation: ‚ÄúSelf-Play is Automated Knowledge Creation.‚Äú ‚Äî Carlos E. Perez Transfer learning is the key to go from self-play to the real world. Explaining AlphaGo: Interpreting Contextual Effects in Neural Networks ‚Äî Zenan Ling, Haotian Ma, Yu Yang, Robert C. Qiu, Song-Chun Zhu, Quanshi Zhang Deep Learning: AlphaGo Zero Explained In One Picture ‚Äî L.V. How to build your own AlphaZero AI using Python and Keras ‚Äî David Foster An open-source implementation of the AlphaGoZero algorithm ‚Äî TensorFlow ELF OpenGo: An Open Reimplementation of AlphaZero ‚Äî Tian et al. TensorFlow.js Implementation of DeepMind‚Äôs AlphaZero Algorithm for Chess. Live Demo | Code ‚Äî Fran√ßois Pays 2.4 Multi-Agent Populations Machine Theory of Mind ‚Äî Rabinowitz et al. A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning ‚Äî Lanctot et al. Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments ‚Äî Al-Shedivat et al. Intrinsic Social Motivation via Causal Influence in Multi-Agent RL ‚Äî Natasha Jaques, Angeliki Lazaridou, Edward Hughes, Caglar Gulcehre, Pedro A. Ortega, DJ Strouse, Joel Z. Leibo, Nando de Freitas Autonomous Agents Modelling Other Agents: A Comprehensive Survey and Open Problems ‚Äî Stefano V. Albrecht, Peter Stone Learning with Opponent-Learning Awareness Paper | Blog ‚Äî OpenAI GPU-Accelerated Robotic Simulation for Distributed Reinforcement Learning Paper | Blog ‚Äî Jacky Liang, Viktor Makoviychuk, Ankur Handa, Nuttapong Chentanez, Miles Macklin, Dieter Fox, NVIDIA Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments Paper | Blog | Code ‚Äî OpenAI 2.5 Deep Meta-LearningLearning to Learn. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. A meta-learning algorithm takes in a distribution of tasks, where each task is a learning problem, and it produces a quick learner ‚Äî a learner that can generalize from a small number of examples. Learning to Learn Paper | Code ‚Äî Google DeepMind, University of Oxford, Canadian Institute for Advanced Research Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks ‚Äî Chelsea Finn, Pieter Abbeel, Sergey Levine AutoML: Methods, Systems, Challenges ‚Äî Frank Hutter, Lars Kotthoff, Joaquin Vanschoren Causal Reasoning from Meta-reinforcement Learning ‚Äî Ishita Dasgupta, Jane Wang, Silvia Chiappa, Jovana Mitrovic, Pedro Ortega, David Raposo, Edward Hughes, Peter Battaglia, Matthew Botvinick, Zeb Kurth-Nelson The Evolved Transformer ‚Äî David R. So, Chen Liang, Quoc V. Le Talos: Hyperparameter Scanning and Optimization for Keras ‚Äî Autonomio EAT-NAS: Elastic Architecture Transfer for Accelerating Large-scale Neural Architecture Search ‚Äî Jiemin Fang, Yukang Chen, Xinbang Zhang, Qian Zhang, Chang Huang, Gaofeng Meng, Wenyu Liu, Xinggang Wang FIGR: Few-shot Image Generation with Reptile ‚Äî Louis Clou√¢tre, Marc Demers Efficient Neural Architecture Search via Parameter Sharing Paper | Code ‚Äî Hieu Pham, Melody Y. Guan, Barret Zoph, Quoc V. Le, Jeff Dean Meta-Learning Shared Hierarchies Paper | Blog | Code ‚Äî OpenAI Learning Unsupervised Learning Rules ‚Äî Luke Metz, Niru Maheswaranathan, Brian Cheung, Jascha Sohl-Dickstein Reptile: A Scalable Meta-Learning Algorithm ‚Äî Alex Nichol, John Schulman Learning Shared Dynamics with Meta-World Models ‚Äî Lisheng Wu, Minne Li, Jun Wang NIPS2017 Meta Learning Symposium videos ‚Äî NIPS 2017 Colaboratory reimplementation of MAML in TF 2.0 ‚Äî Marianne Linhares Monteiro ‚ÄúThe notion of a neural ‚Äúarchitecture‚Äù is going to disappear thanks to meta learning.‚Äú ‚Äî Andrew Trask 3. Environments3.1 OpenAI Gym OpenAI Gym WebSite | Blog | GitHub | White Paper ‚Äî OpenAI 3.2 Unity ML-Agents Unity ML-Agents WebSite | GitHub | Documentation | Challenge I ‚Äî Unity Technologies Puppo, The Corgi: Cuteness Overload with the Unity ML-Agents Toolkit ‚Äî Vincent-Pierre Berges, Leon Chen 3.3 DeepMind Control Suite DeepMind Control Suite Paper | GitHub | Video ‚Äî DeepMind 3.4 Brigham Young University | Holodeck BYU Holodeck: A high-fidelity simulator for deep reinforcement learning Website | GitHub | Documentation ‚Äî Brigham Young University 3.5 Facebook‚Äôs Horizon Horizon: Facebook‚Äôs Open Source Applied Reinforcement Learning Platform Paper | GitHub | Blog ‚Äî Jason Gauci, Edoardo Conti, Yitao Liang, Kittipat Virochsiri, Yuchen He, Zachary Kaden, Vivek Narayanan, Xiaohui Ye 3.6 PhysX PhysX SDK, an Open-Source Physics Engine GitHub | Blog ‚Äî NVIDIA 4. General Readings, Ressources and Tools Building safe artificial intelligence: specification, robustness, and assurance ‚Äî Pedro A. Ortega, Vishal Maini, and the DeepMind safety team Google Dataset Search Beta ‚Äî Google Papers with Code ‚Äî Papers with Code GitXiv | arXiv + CODE ‚Äî Collaborative Open Computer Science Best Paper Awards in Computer Science (since 1996) ‚Äî Jeff Huang The Vulnerable World Hypothesis ‚Äî Nick Bostrom Podcast: Existential Hope in 2019 and Beyond ‚Äî Ariel Conn Scalable agent alignment via reward modeling Medium | arXiv ‚Äî Jan Leike, David Krueger, Tom Everitt, Miljan Martic, Vishal Maini, Shane Legg The 2018 AI Index report ‚Äî Yoav Shoham, Raymond Perrault, Erik Brynjolfsson, Jack Clark, James Manyika, Juan Carlos Niebles, Terah Lyons, John Etchemendy, Barbara Grosz, Zoe Bauer ASILOMAR AI PRINCIPLES ‚Äî The 2017 Asilomar conference Strategic Implications of Openness in AI Development ‚Äî Nick Bostrom ‚Äú(AI) will rank among our greatest technological achievements, and everyone deserves to play a role in shaping it.‚Äú ‚Äî Fei-Fei Li Artificial Intelligence and Human Rights ‚Äî Jessica Fjeld, Hannah Hilligoss, Nele Achten, Maia Levy Daniel, Sally Kagay, and Joshua Feldman (Visualization Designed By: Arushi Singh) teleportHQ ThinkToCode ecosystem ‚Äî teleportHQ Statistical physics of liquid brains ‚Äî Jordi Pinero and Ricard Sole Reframing Superintelligence ‚Äî K. Eric Drexler Interpretable Machine Learning ‚Äî Christoph Molnar Building a Winning Self-Driving Car in Six Months ‚Äî Keenan Burnett, Andreas Schimpe, Sepehr Samavi, Mona Gridseth, Chengzhi Winston Liu, Qiyang Li, Zachary Kroeze, Angela P. Schoellig Une intelligence artificielle bien r√©elle : les termes de l‚ÄôIA ‚Äî Office qu√©b√©cois de la langue fran√ßaise How to deliver on Machine Learning projects ‚Äî Emmanuel Ameisen The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation ‚Äî Miles Brundage, Shahar Avin, Jack Clark, Helen Toner, Peter Eckersley, Ben Garfinkel, Allan Dafoe, Paul Scharre, Thomas Zeitzoff, Bobby Filar, Hyrum Anderson, Heather Roff, Gregory C. Allen, Jacob Steinhardt, Carrick Flynn, Se√°n √ì h√âigeartaigh, Simon Beard, Haydn Belfield, Sebastian Farquhar, Clare Lyle, Rebecca Crootof, Owain Evans, Michael Page, Joanna Bryson, Roman Yampolskiy, Dario Amodei Machine Learning for Combinatorial Optimization: a Methodological Tour d‚ÄôHorizon ‚Äî Yoshua Bengio, Andrea Lodi, Antoine Prouvost 26-Year-Old Nigerian Creates First Gaming Robot ‚Äî Christina Santi Machine Learning Top 10 Articles for the Past Month (v.Oct 2018) ‚Äî Mybridge Is artificial intelligence set to become art‚Äôs next medium? ‚Äî Jonathan Bastable, Christie‚Äôs Phrase-Based &amp; Neural Unsupervised Machine Translation arXiv | Code | Blog ‚Äî Guillaume Lample, Myle Ott, Alexis Conneau, Ludovic Denoyer, Marc‚ÄôAurelio Ranzato Tensor Considered Harmful ‚Äî Alexander Rush An Artificial Neuron Implemented on an Actual Quantum Processor ‚Äî Tacchino et al. Efficiently measuring a quantum device using machine learning ‚Äî D.T. Lennon, H. Moon, L.C. Camenzind, Liuqi Yu, D.M. Zumb√ºhl, G.A.D. Briggs, M.A. Osborne, E.A. Laird, N. Ares Deep Learning : Current Limits and What Lies Beyond Them ‚Äî Fran√ßois Chollet Open-ended Learning in Symmetric Zero-sum Games ‚Äî David Balduzzi, Marta Garnelo, Yoram Bachrach, Wojtek Czarnecki, Julien Perolat, Max Jaderberg, Thore Graepel Poker | Solving Imperfect-Information Games via Discounted Regret Minimization ‚Äî Noam Brown, Tuomas Sandholm Automatically Generating Comments for Arbitrary Source Code) ‚Äî Jessica Moore The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning) ‚Äî Jay Alammar 10 Exciting Ideas of 2018 in NLP ‚Äî Sebastian Ruder Deconstructing BERT: Distilling 6 Patterns from 100 Million Parameters ‚Äî Jesse Vig Learning to Infer Graphics Programs from Hand-Drawn Images ‚Äî Kevin Ellis, Daniel Ritchie, Armando Solar-Lezama, Joshua B. Tenenbaum TensorFlow code and pre-trained models for BERT (Bidirectional Encoder Representations from Transformers) ‚Äî Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova The Superintelligent Will: Motivation and Instrumental Rationality in Advanced Artificial Agents ‚Äî Nick Bostrom MobiLimb: Augmenting Mobile Devices with a Robotic Limb ‚Äî Marc Teyssier, Gilles Bailly, Catherine Pelachaud, Eric Lecolinet 32-Legged Spherical Robot Moves Like an Amoeba ‚Äî Evan Ackerman, IEEE Spectrum On winning all the big academic recent competitions. Presentation. ‚Äî Megvii (Face++) Team Stanford AI recreates chemistry‚Äôs periodic table of elements ‚Äî Ker Than Neural Approaches to Conversational AI ‚Äî Jianfeng Gao, Michel Galley, Lihong Li Learned optimizers that outperform SGD on wall-clock and validation loss ‚Äî Luke Metz, Niru Maheswaranathan, Jeremy Nixon, C. Daniel Freeman, Jascha Sohl-Dickstein Beauty and the Beast: Optimal Methods Meet Learning for Drone Racing ‚Äî Elia Kaufmann, Mathias Gehrig, Philipp Foehn, Ren√© Ranftl, Alexey Dosovitskiy, Vladlen Koltun, Davide Scaramuzza Writing Code for NLP Research ‚Äî Allen Institute for Artificial Intelligence Autonomous Tidying-up Robot System ‚Äî Preferred Networks Emerging Technology and Ethics Research Guide ‚Äì v 1.0 ‚Äî Danya Glabau Machine learning and artificial intelligence in the quantum domain ‚Äî Vedran Dunjko, Hans J. Briegel Playing Mortal Kombat with TensorFlow.js. Transfer learning and data augmentation ‚Äî Minko Gechev A series on quantum computing? Welcome to QuantumCasts! ‚Äî Marissa Giustina NLP.js : a general natural language utilities for nodejs ‚Äî AXA Shared Services Spain S.A. Hierarchical Multi-Task Learning model: One NLP model to rule them all! Medium | Demo | Code ‚Äî Hugging Face Constructing exact representations of quantum many-body systems with deep neural networks ‚Äî Giuseppe Carleo Over 200 of the Best Machine Learning, NLP, and Python Tutorials ‚Äî 2018 Edition ‚Äî Robbie Allen Deep Learning Papers Reading Roadmap ‚Äî Flood Sung Learn Machine Learning from Top 50 Articles for the Past Year (v.2019) ‚Äî Mybridge Open Courses and Textbooks ‚Äî Samuel G. Finlayson ~250 awesome short lectures on robotics ‚Äî Queensland University of Technology Robot Academy The Best Textbooks on Every Subject ‚Äî lukeprog ‚ÄúML paper writing pro-tip: you can download the raw source of any arxiv paper. Click on the ‚ÄúOther formats‚Äù link, then click ‚ÄúDownload source‚Äù. This gets you a .tar.gz with all the .tex files, all the image files for the figures in their original resolution, etc.‚Äú ‚Äî Ian Goodfellow !function(f,b,e,v,n,t,s) {if(f.fbq)return;n=f.fbq=function(){n.callMethod? n.callMethod.apply(n,arguments):n.queue.push(arguments)}; if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version=‚Äô2.0‚Äô; n.queue=[];t=b.createElement(e);t.async=!0; t.src=v;s=b.getElementsByTagName(e)[0]; s.parentNode.insertBefore(t,s)}(window, document,‚Äôscript‚Äô, ‚Äòhttps://connect.facebook.net/en_US/fbevents.js&#39;); fbq(‚Äòinit‚Äô, ‚Äò587955031642222‚Äô); fbq(‚Äòtrack‚Äô, ‚ÄòPageView‚Äô); Group Reservation : ‚úâÔ∏è Email Us : info@montreal.aiüìû Phone : +1.514.829.8269üåê Website : http://www.montreal.aiüìù LinkedIn : https://www.linkedin.com/in/montrealaiüèõ Headquarters : 350, PRINCE-ARTHUR STREET W., SUITE #2105, MONTREAL [QC], CANADA, H2X 3R4 *Administrative Head Office #AIFirst #MontrealAI #MontrealAIAcademy #MontrealArtificialIntelligence","link":"/MontrealAI.github.io/academy/index copy.html"},{"title":"MONTR√âAL.AI | Montr√©al Artificial Intelligence","text":"MONTR√âAL.AI EVENTSSalon | Press Dinner | Concert | Art Auction | Charity Gala ‚ùñ MONTREAL.AI SalonMeeting of Influential Montr√©al AI People at the House of Famous People ‚ùñ MONTREAL.AI Press DinnerHonoring Award-Winning AI Journalism ‚ùñ MONTREAL.AI‚Äôs Fine Arts AuctionUnveilling a World of Hidden Secrets On October 25, 2018, the first artificial intelligence artwork ever sold at Christie‚Äôs auction house shattered expectations, fetching $432,500. Today, the House of Montr√©al.AI Fine Arts introduces : Montr√©al.AI‚Äôs Fine Arts Auction, the first international auction dedicated to quintessential fine AI arts : ‚ÄúUnveilling a World of Hidden Secrets‚Äù. ‚ÄúThe Artists Creating with AI Won‚Äôt Follow Trends; THEY WILL SET THEM.‚Äú ‚Äî Montr√©al.AI Fine Arts We are getting ready for the first auction. Top art collectors will be able to place bids internationally. ‚ùñ MONTREAL.AI Academy : Artificial Intelligence 101Training the individuals who, with AI, will shape the 21st CenturyAI 101: For the Newcomers to Artificial Intelligence!On Tue, Nov 26, 2019 | 6:30 PM - 8:30 PM EST, the General Secretariat of MONTREAL.AI will present, with authority: ‚ÄúArtificial Intelligence 101: The First World-Class Overview of AI for the General Public‚Äú. Location: NRH Prince Arthur - Ballroom, 3625 Avenue du Parc, Montreal (Qu√©bec), Canada, H2X 3P8. Artificial Intelligence 101 : Buy Tickets on EventbriteBuy Tickets on Eventbrite var exampleCallback = function() { console.log('Order complete!'); }; window.EBWidgets.createWidget({ widgetType: 'checkout', eventId: '68213946751', modal: true, modalTriggerElementId: 'eventbrite-widget-modal-trigger-68213946751', onOrderComplete: exampleCallback }); ‚Äú(AI) will rank among our greatest technological achievements, and everyone deserves to play a role in shaping it.‚Äú ‚Äî Fei-Fei Li Tickets and Group ReservationGroup Reservation: : secretariat@montreal.ai Tickets: https://ai101montreal.eventbrite.ca Language: Tutorial given in English.Date And Time: Tue, 26 November 2019 | 6:30 PM ‚Äì 8:30 PM ESTLocation: NRH Prince Arthur - Ballroom, 3625 Avenue du Parc, Montreal (Qu√©bec), Canada, H2X 3P8. var exampleCallback = function() { console.log('Order complete!'); }; window.EBWidgets.createWidget({ // Required widgetType: 'checkout', eventId: '68213946751', iframeContainerId: 'eventbrite-widget-container-68213946751', // Optional iframeContainerHeight: 425, // Widget height in pixels. Defaults to a minimum of 425px if not provided onOrderComplete: exampleCallback // Method called when an order has successfully completed }); ‚ùñ MONTREAL.AI OrchestraPioneering Superhuman Symphonies var exampleCallback = function() { console.log('Order complete!'); }; window.EBWidgets.createWidget({ // Required widgetType: 'checkout', eventId: '59763841258', iframeContainerId: 'eventbrite-widget-container-59763841258', // Optional iframeContainerHeight: 425, // Widget height in pixels. Defaults to a minimum of 425px if not provided onOrderComplete: exampleCallback // Method called when an order has successfully completed }); ‚ùñ MONTREAL.AI‚Äôs Ambassadors Dinner ‚ùñ MONTREAL.AI‚Äôs Fireside Chat ‚ùñ MONTREAL.AI‚Äôs GalaHonoring Award-Winning Captains of Industries, Luminaries and Scholars ‚ÄúIt‚Äôs springtime for AI, and we‚Äôre anticipating a long summer.‚Äú ‚Äî Bill Braun, CIO of Chevron ‚úâÔ∏è Email Us : info@montreal.aiüìû Phone : +1.514.829.8269üåê Website : http://www.montreal.aiüìù LinkedIn : https://www.linkedin.com/in/montrealaiüèõ Headquarters : 350, PRINCE-ARTHUR STREET W., SUITE #2105, MONTREAL [QC], CANADA, H2X 3R4 *Administrative Head Office #AIFirst #Chief AI Officers #MontrealAI #MontrealArtificialIntelligence","link":"/MontrealAI.github.io/events/index.html"}],"posts":[{"title":"Montr√©al Artificial Intelligence","text":"MONTR√âAL.AI | Montr√©al Artificial Intelligence MONTR√âAL.AI : The Keystone of the AI IndustryAI is Capable of Profoundly Transforming Industries and Societies.MONTR√âAL.AI (EST‚ÄôB‚ÄôD 2003) | Montr√©al Artificial Intelligence, a research company at the forefront of the AI field, is developing and commercializing the most significant general-purpose technology ever created. After building Canada‚Äôs largest artificial intelligence community , it‚Äôs time to build the largest AI business in Montreal: MONTR√âAL.AI. MONTR√âAL.AI aims for unicorn status. We are on the dawn of The Age of Artificial Intelligence. A High-Stakes Gameüåê Task Force http://montreal.ai/taskforce.jpg Montr√©al.AI Joint Transformative AI Engineering Task Force‚ÄúSuccessful business strategy is about actively shaping the game you play, not just playing the game you find‚Äú ‚Äî The Right Game: Use Game Theory to Shape Strategy | A. Brandenburger &amp; B. Nalebuff The Montr√©al.AI‚Äôs Joint Transformative AI Engineering Task Force, operating unilaterally or in combination with multinational and interagency partners (national and international organizations), is accountable for the pre-eminent deployment and orchestration of the Montr√©al AI-First Conglomerate Overarching Program in order to powerfully scale AI to global industrial landscapes, to pioneer AI-first systemic business advantages and to win the AI race . Montr√©al Artificial Intelligence harnesses the fundamentals of artificial intelligence on a truly global scale and put them to strategically leverage enterprises, governments and institutions with precision engineering. MONTR√âAL.AI‚Äôs Umbrella : Montr√©al AI-First ConglomerateArtificial intelligence is able to enhance prosperity and to settle planetary-scale problems. Under MONTR√âAL.AI‚Äôs umbrella, riding on the phenomenal exponential of AI progress, multiple companies and organisation are being structured to apply hugely impactful pre-AGI technologies in ways never thought of. Montr√©al.AI is starting an effort reaching out to Captains of Industry, Iconic Tech Entrepreneurs, Luminaries, Philanthropists, Scholars and Successful Financiers to join us at boardroom level in this task of historic proportions. ‚ùñ Montreal.AI AcademyTraining the individuals who, with AI, will shape the 21st Century. MONTREAL.AI is preparing a Global Network of Education Centers to pioneer an impactful understanding of AI and to foster a vector for safe humanitarian artificial general intelligence (AGI). The Montreal.AI Academy democratizes artificial intelligence to empower humanity in all its forms. ‚ùñ Montr√©al.AI Fine ArtsPioneering legendary fine AI arts opening the doors to the AI art movement. Captivating a discerning audience and causing a huge stir amongst top art collectors and the most iconoclastic figures, Montr√©al.AI Fine Arts reflects the conceptual richness and ‚Äòpurist‚Äô form of AI creativity expressed by the machine. We are preparing a worldwide PR campaing with major talk show appearances and a TV documentary. ‚ùñ Montr√©al.AI Fine ConsultingConsulting the right AI leader can significantly increase your odds of business success. MONTREAL.AI develops and trains completion-oriented women and men with the determination to ensure a fully ‚ÄòJoint Artificial Intelligence Consulting Workforce‚Äò : Operationally, organizationally, and technically. ‚Äú We want to see more widespread matrix interoperability, individual and life-long learning opportunities and development of Chief AI Officers who possess the knowledges, the skills and the competencies to orchestrate impactful breakthroughs and tangible economic growth for Fortune 500, governments and interagency partners in full compliance with our masterplan : The Montr√©al AI-First Conglomerate Overarching Program.‚Äú Montreal.AI Research: The Apollo Program for AGIThe Grand Challenge for AI Research. #AGIFirstArtificial General Intelligence (AGI) is the most ambitious scientific quest in human history. Under the Montreal.AI‚Äòs umbrella, Montreal.AI Research is launching the Apollo program for AGI to pioneer the general-purpose technology, the holy grail of AI, that will define the future. We are at the verge of a global technological shift.Montreal.AI Research‚Äôs immediate priorities are to orchestrate AGI-First systemic breakthroughs to solve planetary-scale challenges and to pioneer a new era of superhuman scientific discoveries. Who do you turn to if you seek out the very best in Artificial Intelligence?MONTR√âAL.AI‚Äôs little black book holds the connections, insider knowledge and numbers to help you out. ‚úâÔ∏è Email Us : info@montreal.aiüìû Phone : +1.514.829.8269üåê Website : http://www.montreal.ai/üìù LinkedIn : https://www.linkedin.com/in/montrealai/üèõ Headquarters : 350, PRINCE-ARTHUR STREET W., SUITE #2105, MONTREAL [QC], CANADA, H2X 3R4 *Administrative Head Office #AIFirst #MontrealAI #MontrealArtificialIntelligence","link":"/MontrealAI.github.io/2018/06/27/index/"}],"tags":[],"categories":[]}